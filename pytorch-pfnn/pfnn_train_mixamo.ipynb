{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import skeletonDefMixamo as skd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PhaseFunctionedNetwork import PhaseFunctionedNetwork\n",
    "\n",
    "# set seeds for reproduceability\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "rng = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# X = np.float32(np.loadtxt('./data/Input.txt'))\n",
    "# Y = np.float32(np.loadtxt('./data/Output.txt'))\n",
    "# P = np.float32(np.loadtxt('./data/Phases.txt'))\n",
    "# print(X.shape, Y.shape, P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phases(X_input_arr):\n",
    "    phase = np.linspace(0, 2*np.pi, num=X_input_arr.shape[0])\n",
    "    return phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idle data shape: (995, 888), (995, 819), (995,)\n",
      "Jump Forward BIG data shape: (169, 888), (169, 819), (169,)\n",
      "Jump Forward SMALL data shape: (112, 888), (112, 819), (112,)\n"
     ]
    }
   ],
   "source": [
    "# Process Data (Note currently this data is NOT MIRRORD, CAN DOUBLE WITH MIRRORING)\n",
    "\n",
    "# Idle Data\n",
    "X_idle = np.float32(np.loadtxt('C:/Users/Ana/Desktop/dev/pfnn-dev/Export/Input_Idle.txt'))\n",
    "Y_idle = np.float32(np.loadtxt('C:/Users/Ana/Desktop/dev/pfnn-dev/Export/Output_Idle.txt'))\n",
    "P_idle = get_phases(X_idle)\n",
    "print(f\"Idle data shape: {X_idle.shape}, {Y_idle.shape}, {P_idle.shape}\")\n",
    "\n",
    "# Big Forward Jump\n",
    "X_jump_for_BIG = np.float32(np.loadtxt('C:/Users/Ana/Desktop/dev/pfnn-dev/Export/Input_jump_for_BIG.txt'))\n",
    "Y_jump_for_BIG = np.float32(np.loadtxt('C:/Users/Ana/Desktop/dev/pfnn-dev/Export/Output_jump_for_BIG.txt'))\n",
    "P_jump_for_BIG = get_phases(X_jump_for_BIG)\n",
    "print(f\"Jump Forward BIG data shape: {X_jump_for_BIG.shape}, {Y_jump_for_BIG.shape}, {P_jump_for_BIG.shape}\")\n",
    "\n",
    "# Small Forward Jump\n",
    "X_jump_for_SMALL = np.float32(np.loadtxt('C:/Users/Ana/Desktop/dev/pfnn-dev/Export/Input_jump_for_SMALL.txt'))\n",
    "Y_jump_for_SMALL = np.float32(np.loadtxt('C:/Users/Ana/Desktop/dev/pfnn-dev/Export/Output_jump_for_SMALL.txt'))\n",
    "P_jump_for_SMALL = get_phases(X_jump_for_SMALL)\n",
    "print(f\"Jump Forward SMALL data shape: {X_jump_for_SMALL.shape}, {Y_jump_for_SMALL.shape}, {P_jump_for_SMALL.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (1276, 888)\n",
      "Y: (1276, 819)\n",
      "P: (1276,)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate Data into indivudal X, Y, P Arrays\n",
    "X = np.concatenate((X_idle, X_jump_for_BIG, X_jump_for_SMALL))\n",
    "print(f\"X: {X.shape}\")\n",
    "\n",
    "Y = np.concatenate((Y_idle, Y_jump_for_BIG, Y_jump_for_SMALL))\n",
    "print(f\"Y: {Y.shape}\")\n",
    "\n",
    "P = np.concatenate((P_idle, P_jump_for_BIG, P_jump_for_SMALL))\n",
    "print(f\"P: {P.shape}\")\n",
    "\n",
    "# Debugging only use idle\n",
    "# X = X_idle\n",
    "# Y = Y_idle\n",
    "# P = P_idle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X mean: (888,)\n",
      "X std: (888,)\n",
      "Y mean: (819,)\n",
      "Y std: (819,)\n"
     ]
    }
   ],
   "source": [
    "# calculate mean and std\n",
    "Xmean, Xstd = X.mean(axis=0), X.std(axis=0)\n",
    "Ymean, Ystd = Y.mean(axis=0), Y.std(axis=0)\n",
    "\n",
    "print(f\"X mean: {Xmean.shape}\")\n",
    "print(f\"X std: {Xstd.shape}\")\n",
    "print(f\"Y mean: {Ymean.shape}\")\n",
    "print(f\"Y std: {Ystd.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_any(num_list, str):\n",
    "    return any(num in str for num in num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parser of Labels\n",
    "labels_path = \"C:/Users/Ana/Desktop/dev/pfnn-dev/Export/InputLabels_Idle.txt\"\n",
    "\n",
    "TRAJ_STR = 'Trajectory'\n",
    "POS_STR = 'Position'\n",
    "DIR_STR = 'Direction'\n",
    "GAIT_STR = 'Style'\n",
    "SPEED_STR = 'Speed'\n",
    "VEL_STR = 'Velocity'\n",
    "JOINT_STR = 'Bone'\n",
    "FORWARD_STR = 'Forward'\n",
    "UP_STR = 'Up'\n",
    "\n",
    "with open(labels_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "past_indices = [str(i) for i in range(0,6)]\n",
    "\n",
    "# All the index arrays to populate for calculating means/std\n",
    "\n",
    "# Trajectory\n",
    "traj_past_pos_idx = []\n",
    "traj_future_pos_idx = []\n",
    "traj_past_dir_idx = []\n",
    "traj_future_dir_idx = []\n",
    "traj_past_vel_idx = []\n",
    "traj_future_vel_idx = []\n",
    "traj_gait_idx = []\n",
    "traj_speed_idx = []\n",
    "\n",
    "# Joints\n",
    "joint_pos = []\n",
    "joint_forward = []\n",
    "joint_up = []\n",
    "joint_vel = []\n",
    "\n",
    "for line in lines:\n",
    "    # Split the line at the first space character to separate index and name\n",
    "    index, name = line.split(maxsplit=1)\n",
    "    index = int(index.strip('[]'))  # Remove the square brackets and convert to int\n",
    "    name = name.strip()  # Remove any surrounding whitespace/newline characters\n",
    "    \n",
    "    # Trajectory parsing logic\n",
    "    if TRAJ_STR in name:\n",
    "        if POS_STR in name:\n",
    "            if contains_any(past_indices, name):\n",
    "                # Past Positions\n",
    "                traj_past_pos_idx.append(index)\n",
    "            else:\n",
    "                # Future Positions\n",
    "                traj_future_pos_idx.append(index)\n",
    "        if DIR_STR in name:\n",
    "            if contains_any(past_indices, name):\n",
    "                # Past Directions\n",
    "                traj_past_dir_idx.append(index)\n",
    "            else:\n",
    "                # Future Directions\n",
    "                traj_future_dir_idx.append(index)\n",
    "        if VEL_STR in name:\n",
    "            if contains_any(past_indices, name):\n",
    "                # Past Velocities\n",
    "                traj_past_vel_idx.append(index)\n",
    "            else:\n",
    "                # Future Velocities\n",
    "                traj_future_vel_idx.append(index)\n",
    "        if GAIT_STR in name:\n",
    "            # Gait\n",
    "            traj_gait_idx.append(index)\n",
    "        if SPEED_STR in name:\n",
    "            # Speed\n",
    "            traj_speed_idx.append(index)\n",
    "    if JOINT_STR in name:\n",
    "        if POS_STR in name:\n",
    "            # Positions X, Y and Z\n",
    "            joint_pos.append(index)\n",
    "        if FORWARD_STR in name:\n",
    "            # Forward translation X, Y and Z\n",
    "            joint_forward.append(index)\n",
    "        if UP_STR in name:\n",
    "            # Upward translations X, Y and Z\n",
    "            joint_up.append(index)\n",
    "        if VEL_STR in name:\n",
    "            # Velocity X, Y and Z\n",
    "            joint_vel.append(index)\n",
    "\n",
    "# Debugging purposes\n",
    "# print(traj_past_pos_idx)\n",
    "# print(traj_future_pos_idx)\n",
    "# print(traj_past_dir_idx)\n",
    "# print(traj_future_dir_idx)\n",
    "# print(traj_gait_idx)\n",
    "# print(traj_speed_idx)\n",
    "# print(traj_past_vel_idx)\n",
    "# print(traj_future_vel_idx)\n",
    "# print(joint_pos)\n",
    "# print(joint_forward)\n",
    "# print(joint_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Input Data\n",
    "Xstd[traj_past_pos_idx] = Xstd[traj_past_pos_idx].mean()  # Trajectory Past Positions\n",
    "Xstd[traj_future_pos_idx] = Xstd[traj_future_pos_idx].mean()  # Trajectory Future Positions\n",
    "Xstd[traj_past_dir_idx] = Xstd[traj_past_dir_idx].mean()  # Trajectory Past Directions\n",
    "Xstd[traj_future_dir_idx] = Xstd[traj_future_dir_idx].mean()  # Trajectory Future Direction\n",
    "Xstd[traj_past_vel_idx] = Xstd[traj_past_vel_idx].mean()  # Trajectory Past Velocities\n",
    "Xstd[traj_future_vel_idx] = Xstd[traj_future_vel_idx].mean()  # Trajectory Future Velocities\n",
    "Xstd[traj_speed_idx] = Xstd[traj_speed_idx].mean()  # Trajectory Speed\n",
    "Xstd[traj_gait_idx] = Xstd[traj_gait_idx].mean()  # Trajectory Gait\n",
    "\n",
    "# mask out unused joints in input\n",
    "joint_weights = np.array(skd.JOINT_WEIGHTS).repeat(3) # Repeat 3 times for X, Y and Z\n",
    "\n",
    "Xstd[joint_pos] = Xstd[joint_pos].mean() / (joint_weights * 0.1) # Joint Positions\n",
    "Xstd[joint_vel] = Xstd[joint_vel].mean() / (joint_weights * 0.1) # Joint Velocities\n",
    "Xstd[joint_forward] = Xstd[joint_forward].mean() / (joint_weights * 0.1) # Joint Forward Translation\n",
    "Xstd[joint_up] = Xstd[joint_up].mean() / (joint_weights * 0.1) # Joint Upward Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[816, 818]\n"
     ]
    }
   ],
   "source": [
    "# Parser of Labels\n",
    "labels_path = 'C:/Users/Ana/Desktop/dev/pfnn-dev/Export/OutputLabels_Idle.txt'\n",
    "\n",
    "ROOT_STR = 'Root'\n",
    "TRANSLATION_STR = 'Translation'\n",
    "\n",
    "with open(labels_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "past_indices = [str(i) for i in range(0,6)]\n",
    "\n",
    "# All the index arrays to populate for calculating means/std\n",
    "\n",
    "# Trajectory\n",
    "traj_pos_idx = []\n",
    "traj_dir_idx = []\n",
    "traj_vel_idx = []\n",
    "\n",
    "# Joints\n",
    "joint_pos = []\n",
    "joint_forward = []\n",
    "joint_up = []\n",
    "joint_vel = []\n",
    "\n",
    "# Root\n",
    "root_translation = []\n",
    "\n",
    "for line in lines:\n",
    "    # Split the line at the first space character to separate index and name\n",
    "    index, name = line.split(maxsplit=1)\n",
    "    index = int(index.strip('[]'))  # Remove the square brackets and convert to int\n",
    "    name = name.strip()  # Remove any surrounding whitespace/newline characters\n",
    "    \n",
    "    # Trajectory parsing logic\n",
    "    if TRAJ_STR in name:\n",
    "        if POS_STR in name:\n",
    "            traj_pos_idx.append(index)\n",
    "        if DIR_STR in name:\n",
    "            traj_dir_idx.append(index)\n",
    "        if VEL_STR in name:\n",
    "            traj_vel_idx.append(index)\n",
    "    # Joint parsing logic\n",
    "    if JOINT_STR in name:\n",
    "        if POS_STR in name:\n",
    "            joint_pos.append(index)\n",
    "        if FORWARD_STR in name:\n",
    "            joint_forward.append(index)\n",
    "        if UP_STR in name:\n",
    "            joint_up.append(index)\n",
    "        if VEL_STR in name:\n",
    "            joint_vel.append(index)\n",
    "    # Root parsin logic\n",
    "    if ROOT_STR in name:\n",
    "        if TRANSLATION_STR in name:\n",
    "            root_translation.append(index)\n",
    "\n",
    "# Debugging Purposes\n",
    "print(root_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Output Data\n",
    "\n",
    "# Trajectory\n",
    "Ystd[traj_pos_idx] = Ystd[traj_pos_idx].mean()\n",
    "Ystd[traj_dir_idx] = Ystd[traj_dir_idx].mean()\n",
    "Ystd[traj_vel_idx] = Ystd[traj_vel_idx].mean()\n",
    "\n",
    "# Joints\n",
    "Ystd[joint_pos] = Ystd[joint_pos].mean()\n",
    "Ystd[joint_forward] = Ystd[joint_forward].mean()\n",
    "Ystd[joint_up] = Ystd[joint_up].mean()\n",
    "Ystd[joint_vel] = Ystd[joint_vel].mean()\n",
    "\n",
    "# Root\n",
    "Ystd[root_translation] = Ystd[root_translation].mean()\n",
    "\n",
    "# save mean / std / min / max\n",
    "\n",
    "Xmean.astype(np.float32).tofile('./weights/Xmean.bin')\n",
    "Ymean.astype(np.float32).tofile('./weights/Ymean.bin')\n",
    "Xstd.astype(np.float32).tofile('./weights/Xstd.bin')\n",
    "Ystd.astype(np.float32).tofile('./weights/Ystd.bin')\n",
    "\n",
    "# normalize data\n",
    "X = (X - Xmean) / Xstd\n",
    "Y = (Y - Ymean) / Ystd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape torch.Size([1276, 889])\n",
      "Target shape torch.Size([1276, 819])\n"
     ]
    }
   ],
   "source": [
    "# append phase as additional feature\n",
    "input = torch.tensor(np.concatenate([X, P [..., np.newaxis]], axis=-1))\n",
    "target = torch.tensor(Y)\n",
    "\n",
    "print(f\"Input shape {input.shape}\")\n",
    "print(f\"Target shape {target.shape}\")\n",
    "\n",
    "dataset = TensorDataset(input, target)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure GPU is available\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "device = \"cuda\"\n",
    "\n",
    "# custom loss function\n",
    "def loss_func(output, target, model):\n",
    "    loss = torch.mean((output - target)**2) + model.cost()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:03<00:00, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 0.26744564927094894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = PhaseFunctionedNetwork(input_shape=input.shape[1], output_shape=target.shape[1])\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "epochs=1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loss_list = []\n",
    "    for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "        input, target = batch\n",
    "        input, target = input.to(device), target.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        output = model(input)\n",
    "        loss = loss_func(output, target, model)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {np.average(loss_list)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights\n",
    "model.precompute_and_save_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
