{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import skeletonDefMixamo as skd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PhaseFunctionedNetwork import PhaseFunctionedNetwork\n",
    "\n",
    "# set seeds for reproduceability\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "rng = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# X = np.float32(np.loadtxt('./data/Input.txt'))\n",
    "# Y = np.float32(np.loadtxt('./data/Output.txt'))\n",
    "# P = np.float32(np.loadtxt('./data/Phases.txt'))\n",
    "# print(X.shape, Y.shape, P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phases(X_input_arr):\n",
    "    print(X_input_arr.shape[0]/2)\n",
    "    # phase = np.linspace(0, 2*np.pi, num=X_input_arr.shape[0])\n",
    "    # return phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_phases(n_elements):\n",
    "#     # Determine the size of each segment (one-third of the total elements)\n",
    "#     segment_size = n_elements // 3\n",
    "    \n",
    "#     # Create arrays for each segment\n",
    "#     first_segment = np.zeros(segment_size)\n",
    "#     second_segment = np.full(segment_size, np.pi)\n",
    "#     third_segment = np.full(segment_size, 2 * np.pi)\n",
    "    \n",
    "#     # Concatenate the segments to form the final array\n",
    "#     custom_array = np.concatenate((first_segment, second_segment, third_segment))\n",
    "    \n",
    "#     # If n_elements is not exactly divisible by 3, pad the array to reach the desired size\n",
    "#     if custom_array.size < n_elements:\n",
    "#         pad_size = n_elements - custom_array.size\n",
    "#         custom_array = np.pad(custom_array, (0, pad_size), 'constant', constant_values=(2 * np.pi,))\n",
    "    \n",
    "#     return custom_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idle data shape: (1990, 888), (1990, 819), (1990,)\n",
      "Jump Forward BIG data shape: (338, 888), (338, 819), (338,)\n",
      "Jump Forward SMALL data shape: (224, 888), (224, 819), (224,)\n",
      "Jump Up BIG data shape: (158, 888), (158, 819), (158,)\n",
      "Jump Up SMALL data shape: (158, 888), (158, 819), (158,)\n"
     ]
    }
   ],
   "source": [
    "# Process Data (Note currently this data is NOT MIRRORD, CAN DOUBLE WITH MIRRORING)\n",
    "\n",
    "# Idle Data\n",
    "X_idle = np.float32(np.loadtxt('C:/Users/Ana/Desktop/dev/pfnn-dev/Export/Input_Idle_MIRROR.txt'))\n",
    "Y_idle = np.float32(np.loadtxt('C:/Users/Ana/Desktop/dev/pfnn-dev/Export/Output_Idle_MIRROR.txt'))\n",
    "# phase hack\n",
    "idle_phase_1 = np.linspace(0, 2*np.pi, num=995)\n",
    "idle_phase_2 = np.linspace(0, 2*np.pi, num=995)\n",
    "P_idle = np.concatenate((idle_phase_1, idle_phase_2))\n",
    "print(f\"Idle data shape: {X_idle.shape}, {Y_idle.shape}, {P_idle.shape}\")\n",
    "\n",
    "# # Big Forward Jump\n",
    "X_jump_for_BIG = np.float32(np.loadtxt('C:/Users/Ana/Desktop/dev/pfnn-dev/Export/Input_jump_for_BIG_MIRROR.txt'))\n",
    "Y_jump_for_BIG = np.float32(np.loadtxt('C:/Users/Ana/Desktop/dev/pfnn-dev/Export/Output_jump_for_BIG_MIRROR.txt'))\n",
    "# phase hack\n",
    "jump_for_BIG_phase_1 = np.linspace(0, 2*np.pi, num=169)\n",
    "jump_for_BIG_phase_2 = np.linspace(0, 2*np.pi, num=169)\n",
    "P_jump_for_BIG = np.concatenate((jump_for_BIG_phase_1, jump_for_BIG_phase_2))\n",
    "print(f\"Jump Forward BIG data shape: {X_jump_for_BIG.shape}, {Y_jump_for_BIG.shape}, {P_jump_for_BIG.shape}\")\n",
    "\n",
    "# Small Forward Jump\n",
    "X_jump_for_SMALL = np.float32(np.loadtxt('C:/Users/Ana/Desktop/dev/pfnn-dev/Export/Input_jump_for_SMALL_MIRROR.txt'))\n",
    "Y_jump_for_SMALL = np.float32(np.loadtxt('C:/Users/Ana/Desktop/dev/pfnn-dev/Export/Output_jump_for_SMALL_MIRROR.txt'))\n",
    "# phase hack\n",
    "jump_for_SMALL_phase_1 = np.linspace(0, 2*np.pi, num=112)\n",
    "jump_for_SMALL_phase_2 = np.linspace(0, 2*np.pi, num=112)\n",
    "P_jump_for_SMALL = np.concatenate((jump_for_SMALL_phase_1, jump_for_SMALL_phase_2))\n",
    "print(f\"Jump Forward SMALL data shape: {X_jump_for_SMALL.shape}, {Y_jump_for_SMALL.shape}, {P_jump_for_SMALL.shape}\")\n",
    "\n",
    "# Big Up Jump\n",
    "X_jump_up_BIG = np.float32(np.loadtxt('C:/Users/Ana/Desktop/dev/pfnn-dev/Export/Input_jump_up_BIG_MIRROR.txt'))\n",
    "Y_jump_up_BIG = np.float32(np.loadtxt('C:/Users/Ana/Desktop/dev/pfnn-dev/Export/Output_jump_up_BIG_MIRROR.txt'))\n",
    "# phase hack\n",
    "jump_up_BIG_phase_1 = np.linspace(0, 2*np.pi, num=79)\n",
    "jump_up_BIG_phase_2 = np.linspace(0, 2*np.pi, num=79)\n",
    "P_jump_up_BIG = np.concatenate((jump_up_BIG_phase_1, jump_up_BIG_phase_2))\n",
    "print(f\"Jump Up BIG data shape: {X_jump_up_BIG.shape}, {Y_jump_up_BIG.shape}, {P_jump_up_BIG.shape}\")\n",
    "\n",
    "# Small Up Jump\n",
    "X_jump_up_SMALL = np.float32(np.loadtxt('C:/Users/Ana/Desktop/dev/pfnn-dev/Export/Input_jump_up_SMALL_MIRROR.txt'))\n",
    "Y_jump_up_SMALL = np.float32(np.loadtxt('C:/Users/Ana/Desktop/dev/pfnn-dev/Export/Output_jump_up_SMALL_MIRROR.txt'))\n",
    "# phase hack\n",
    "jump_up_SMALL_phase_1 = np.linspace(0, 2*np.pi, num=79)\n",
    "jump_up_SMALL_phase_2 = np.linspace(0, 2*np.pi, num=79)\n",
    "P_jump_up_SMALL = np.concatenate((jump_up_SMALL_phase_1, jump_up_SMALL_phase_2))\n",
    "print(f\"Jump Up SMALL data shape: {X_jump_up_SMALL.shape}, {Y_jump_up_SMALL.shape}, {P_jump_up_SMALL.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (2868, 888)\n",
      "Y: (2868, 819)\n",
      "P: (2868,)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate Data into indivudal X, Y, P Arrays\n",
    "X = np.concatenate((X_idle, X_jump_for_BIG, X_jump_for_SMALL, X_jump_up_BIG, X_jump_up_SMALL))\n",
    "print(f\"X: {X.shape}\")\n",
    "\n",
    "Y = np.concatenate((Y_idle, Y_jump_for_BIG, Y_jump_for_SMALL, Y_jump_up_BIG, Y_jump_up_SMALL))\n",
    "print(f\"Y: {Y.shape}\")\n",
    "\n",
    "P = np.concatenate((P_idle, P_jump_for_BIG, P_jump_for_SMALL, P_jump_up_BIG, P_jump_up_SMALL))\n",
    "print(f\"P: {P.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (2552, 888)\n",
      "Y: (2552, 819)\n",
      "P: (2552,)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate Data into indivudal X, Y, P Arrays\n",
    "X = np.concatenate((X_idle, X_jump_for_BIG, X_jump_for_SMALL))\n",
    "print(f\"X: {X.shape}\")\n",
    "\n",
    "Y = np.concatenate((Y_idle, Y_jump_for_BIG, Y_jump_for_SMALL))\n",
    "print(f\"Y: {Y.shape}\")\n",
    "\n",
    "P = np.concatenate((P_idle, P_jump_for_BIG, P_jump_for_SMALL))\n",
    "print(f\"P: {P.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase logic\n",
    "delta_phase = P[1:] - P[:-1]\n",
    "delta_phase[delta_phase < 0] = (1.0 - P[:-1] + P[1:])[delta_phase < 0]\n",
    "delta_phase = np.append(delta_phase, 2 * np.pi)\n",
    "\n",
    "Y = np.concatenate([Y, delta_phase [..., np.newaxis]], axis=-1)\n",
    "\n",
    "# calculate mean and std\n",
    "Xmean, Xstd = X.mean(axis=0), X.std(axis=0)\n",
    "Ymean, Ystd = Y.mean(axis=0), Y.std(axis=0)\n",
    "\n",
    "for i in range(Xstd.size):\n",
    "    if (Xstd[i]==0):\n",
    "        Xstd[i]=1\n",
    "for i in range(Ystd.size):\n",
    "    if (Ystd[i]==0):\n",
    "        Ystd[i]=1\n",
    "\n",
    "# normalize data\n",
    "X = (X - Xmean) / Xstd\n",
    "Y = (Y - Ymean) / Ystd\n",
    "\n",
    "# save mean / std / min / max\n",
    "\n",
    "Xmean.astype(np.float32).tofile('C:/Users/Ana/Desktop/dev/pfnn-dev/unity-pfnn/Assets/Demo/Dev/Weights/test/Xmean.bin')\n",
    "Ymean.astype(np.float32).tofile('C:/Users/Ana/Desktop/dev/pfnn-dev/unity-pfnn/Assets/Demo/Dev/Weights/test/Ymean.bin')\n",
    "Xstd.astype(np.float32).tofile('C:/Users/Ana/Desktop/dev/pfnn-dev/unity-pfnn/Assets/Demo/Dev/Weights/test/Xstd.bin')\n",
    "Ystd.astype(np.float32).tofile('C:/Users/Ana/Desktop/dev/pfnn-dev/unity-pfnn/Assets/Demo/Dev/Weights/test/Ystd.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape torch.Size([2552, 889])\n",
      "Target shape torch.Size([2552, 820])\n"
     ]
    }
   ],
   "source": [
    "# append phase as additional feature\n",
    "input = torch.tensor(np.concatenate([X, P [..., np.newaxis]], axis=-1))\n",
    "target = torch.tensor(Y)\n",
    "\n",
    "print(f\"Input shape {input.shape}\")\n",
    "print(f\"Target shape {target.shape}\")\n",
    "\n",
    "dataset = TensorDataset(input, target)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure GPU is available\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "device = \"cuda\"\n",
    "\n",
    "# custom loss function\n",
    "def loss_func(output, target, model):\n",
    "    loss = torch.mean((output - target)**2) + model.cost()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:07<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.9233235165065563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:06<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Loss: 0.7177801566682515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:06<00:00, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Loss: 0.6550676562431244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = PhaseFunctionedNetwork(input_shape=input.shape[1], output_shape=target.shape[1])\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "epochs=3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loss_list = []\n",
    "    for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "        input, target = batch\n",
    "        input, target = input.to(device), target.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        output = model(input)\n",
    "        loss = loss_func(output, target, model)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {np.average(loss_list)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights\n",
    "model.precompute_and_save_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
