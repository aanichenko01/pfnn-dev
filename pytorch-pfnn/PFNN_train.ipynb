{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from PhaseFunctionedNetwork import PhaseFunctionedNetwork\n",
    "from train_utils import train_pfnn_thresh\n",
    "\n",
    "# set seeds for reproduceability\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "rng = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUND = 2\n",
    "INPUT_PATH = 'Input_'\n",
    "OUTPUT_PATH = 'Output_'\n",
    "\n",
    "def get_change_in_phase(phase_arr):\n",
    "    change_in_phase =  phase_arr[1:] - phase_arr[:-1]\n",
    "    change_in_phase[change_in_phase < 0] = (1.0 - phase_arr[:-1] + phase_arr[1:])[change_in_phase < 0]\n",
    "    change_in_phase = np.append(change_in_phase, change_in_phase[-1]) #TODO IF BREAKS append 2pi\n",
    "    return change_in_phase\n",
    "\n",
    "def get_phase_acyclic(X_arr):\n",
    "    P_arr = np.linspace(0, 0.99, num=X_arr.shape[0])\n",
    "\n",
    "    return P_arr\n",
    "\n",
    "def get_phase_cyclic(X_arr, num_repetitions):\n",
    "    total_len = X_arr.shape[0]\n",
    "    \n",
    "    cycle_len = total_len // num_repetitions\n",
    "    cycle = np.linspace(0, 0.99, num=cycle_len, endpoint=False)\n",
    "    # Repeat\n",
    "    P_arr = np.tile(cycle, num_repetitions)\n",
    "\n",
    "    # If not long enough add from beggining of cycle\n",
    "    P_arr_len = len(P_arr)\n",
    "    if P_arr_len < total_len:\n",
    "        pad_to = total_len - P_arr_len\n",
    "        P_arr = np.concatenate([P_arr, cycle[:pad_to]])\n",
    "\n",
    "    return P_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PREFIX = 'Input_'\n",
    "OUTPUT_PREFIX = 'Output_'\n",
    "\n",
    "EXTENSION = '.txt'\n",
    "\n",
    "def load_data(data_dir, action_num):\n",
    "    X_arr = np.float32(np.loadtxt(data_dir + INPUT_PREFIX + action_num + EXTENSION))\n",
    "    Y_arr = np.float32(np.loadtxt(data_dir + OUTPUT_PREFIX + action_num + EXTENSION))\n",
    "    \n",
    "    return X_arr, Y_arr\n",
    "\n",
    "def process_data(X_arr, Y_arr, P_arr, delta_phase_arr, num_files, data_dir, split_stats_arr, cyclic_action=True):\n",
    "    prev_data = sum(arr.shape[0] for arr in X_arr) + sum(arr.shape[0] for arr in Y_arr) \n",
    "    for i in range(int(num_files/2)):\n",
    "        input_data, output_data = load_data(data_dir, str(i))\n",
    "\n",
    "        if(cyclic_action):\n",
    "            phase_data = get_phase_cyclic(input_data, 3)\n",
    "        else:\n",
    "            phase_data = get_phase_acyclic(input_data)\n",
    "\n",
    "        change_in_phase = get_change_in_phase(phase_data)\n",
    "\n",
    "        X_arr.append(input_data)\n",
    "        Y_arr.append(output_data)\n",
    "        P_arr = np.append(P_arr, phase_data)\n",
    "        delta_phase_arr = np.append(delta_phase_arr, change_in_phase)\n",
    "\n",
    "    current_data = sum(arr.shape[0] for arr in X_arr) + sum(arr.shape[0] for arr in Y_arr)\n",
    "    split_stats_arr.append(current_data - prev_data)\n",
    "\n",
    "    return X_arr, Y_arr, P_arr, delta_phase_arr, split_stats_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom joint weights for F42 asset\n",
    "JOINT_NUM = 144\n",
    "\n",
    "joint_weights = np.array([\n",
    "    1,                                                  # HIPS\n",
    "    1, 1, 1,                                            # LEFT leg\n",
    "    1e-10, 1e-10, 1e-10, 1,                             # LEFT foot thumb\n",
    "    1,                                                  # LEFT foot toe base\n",
    "    1e-10, 1e-10, 1e-10, 1,                             # LEFT foot index\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # LEFT foot middle\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # LEFT foot ring\n",
    "    1, 1, 1,                                            # RIGHT leg\n",
    "    1e-10, 1e-10, 1e-10, 1,                             # RIGHT foot thumb\n",
    "    1,                                                  # RIGHT foot toe base\n",
    "    1e-10, 1e-10, 1e-10, 1,                             # RIGHT foot index\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # RIGHT foot middle\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # RIGHT foot ring\n",
    "    1, 1, 1, 1,                                         # SPINE\n",
    "    1, 1,                                               # LEFT shoulder\n",
    "    1, 1,                                               # LEFT arm\n",
    "    1,                                                  # LEFT hand\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # LEFT hand index\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # LEFT hand middle\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # LEFT hand ring\n",
    "    1, 1e-10, 1,                                        # LEFT wing feathers large\n",
    "    1, 1e-10, 1,                                        # LEFT wing feathers medium\n",
    "    1,                                                  # LEFT wing feathers small\n",
    "    1, 1, 1, 1, 1, 1, 1,                                # NECK\n",
    "    1,                                                  # HEAD\n",
    "    1e-10, 1e-10,                                       # JAW\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1e-10, 1e-10, 1e-10,    # TONUGE\n",
    "    1e-10, 1e-10, 1e-10,                                # LEFT eye\n",
    "    1e-10, 1e-10, 1e-10,                                # RIGHT eye\n",
    "    1, 1,                                               # RIGHT shoulder\n",
    "    1, 1,                                               # RIGHT arm\n",
    "    1,                                                  # RIGHT hand\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # RIGHT hand index\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # RIGHT hand middle\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # RIGHT hand ring\n",
    "    1, 1e-10, 1,                                        # RIGHT wing feathers large\n",
    "    1, 1e-10, 1,                                        # RIGHT wing feathers medium\n",
    "    1,                                                  # RIGHT wing feathers small\n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1,                          # TAIL\n",
    "    1e-10, 1e-10, 1,                                    # LEFT tail feather\n",
    "    1e-10, 1e-10, 1,                                    # MIDDLE tail feather         \n",
    "    1e-10, 1e-10, 1                                     # RIGHT tail feather \n",
    "])\n",
    "\n",
    "# repeat weights for each joint to represent X, Y and Z\n",
    "joint_weights = joint_weights.repeat(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic processing of idle and jumps\n",
    "ROOT_DIR = 'C:/Users/Ana/Desktop/dev/pfnn-dev/Export/chapter3_experiments/trajectory/v2/'\n",
    "IDLE_DATA_DIR = ROOT_DIR + 'idle/'\n",
    "JUMP_DATA_DIR = ROOT_DIR + 'jump/'\n",
    "\n",
    "split_stats = []\n",
    "X = []\n",
    "Y = []\n",
    "P = np.empty(0)\n",
    "delta_phase = np.empty(0)\n",
    "\n",
    "# Process idle data\n",
    "file_count = sum(1 for filename in os.listdir(IDLE_DATA_DIR) if filename.endswith('.txt'))\n",
    "X, Y, P, delta_phase, split_stats = process_data(X, Y, P, delta_phase, file_count, data_dir=IDLE_DATA_DIR, split_stats_arr=split_stats, cyclic_action=True)\n",
    "\n",
    "# Process jump data\n",
    "file_count = sum(1 for filename in os.listdir(JUMP_DATA_DIR) if filename.endswith('.txt'))\n",
    "X, Y, P, delta_phase, split_stats = process_data(X, Y, P, delta_phase, file_count, data_dir=JUMP_DATA_DIR, split_stats_arr=split_stats, cyclic_action=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape: (226, 960)\n",
      "Output data shape: (226, 892)\n",
      "Phase data shape: (226,)\n",
      "Delta phase shape: (226,)\n",
      "Action 0 = 31.86%\n",
      "Action 1 = 68.14%\n"
     ]
    }
   ],
   "source": [
    "# stack all the arrays on top of each other\n",
    "X = np.vstack(X)\n",
    "Y = np.vstack(Y)\n",
    "delta_phase = delta_phase.flatten()\n",
    "P = P.flatten()\n",
    "Y = np.concatenate([Y, delta_phase [..., np.newaxis]], axis=-1)\n",
    "\n",
    "# print stats \n",
    "print(f\"Input data shape: {X.shape}\")\n",
    "print(f\"Output data shape: {Y.shape}\")\n",
    "print(f\"Phase data shape: {P.shape}\")\n",
    "print(f\"Delta phase shape: {delta_phase.shape}\")\n",
    "\n",
    "# Action 0 --> Idle\n",
    "# Action 1 --> Jump\n",
    "# print data distribution stats (walk/idle) \n",
    "total_data = sum(data for data in split_stats)\n",
    "for i in range(len(split_stats)):\n",
    "    print(f\"Action {i} = {np.round(split_stats[i]/total_data * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_X_2Styles(X_arr):\n",
    "    Xmean, Xstd = X_arr.mean(axis=0), X_arr.std(axis=0)\n",
    "\n",
    "    # lists to keep track of indices for TRAJECTORY\n",
    "    X_traj_pos_indices = []\n",
    "    X_traj_dir_indices = []\n",
    "    X_traj_style_indices = []\n",
    "    X_traj_slope_indices = []\n",
    "\n",
    "    # number of eleements for each trajectory point\n",
    "    w = 8\n",
    "    for i in range(0, 95, w):\n",
    "        X_traj_pos_indices = np.append(X_traj_pos_indices, range(i,i+3)).astype(int)\n",
    "        X_traj_dir_indices = np.append(X_traj_dir_indices, range(i+3,i+5)).astype(int)\n",
    "        X_traj_slope_indices = np.append(X_traj_slope_indices, i+5).astype(int)\n",
    "        X_traj_style_indices = np.append(X_traj_style_indices, range(i+6,i+8)).astype(int)\n",
    "\n",
    "    # lists to keep track of indices for JOINTS\n",
    "    X_joint_pos_indices = []\n",
    "    X_joint_vel_indices = []\n",
    "\n",
    "    # num of elements for each joint\n",
    "    w = 6\n",
    "    for i in range(96, 959, w):\n",
    "        X_joint_pos_indices = np.append(X_joint_pos_indices, range(i,i+3)).astype(int)\n",
    "        X_joint_vel_indices = np.append(X_joint_vel_indices, range(i+3,i+6)).astype(int)\n",
    "\n",
    "    # INPUT Trajectory data\n",
    "    Xstd[X_traj_pos_indices] = Xstd[X_traj_pos_indices].mean()\n",
    "    Xstd[X_traj_dir_indices] = Xstd[X_traj_dir_indices].mean()\n",
    "    Xstd[X_traj_style_indices] = Xstd[X_traj_style_indices].mean()\n",
    "    Xstd[X_traj_slope_indices] = Xstd[X_traj_slope_indices].mean()\n",
    "\n",
    "    # INPUT Joint data \n",
    "    Xstd[X_joint_pos_indices] = Xstd[X_joint_pos_indices].mean() / (joint_weights * 0.1)\n",
    "\n",
    "    return Xmean, Xstd\n",
    "\n",
    "def preprocess_Y(Y_arr):\n",
    "    Ymean, Ystd = Y_arr.mean(axis=0), Y_arr.std(axis=0)\n",
    "\n",
    "    # PREPROCESS OUTPUT Y\n",
    "    # lists to keep track of indices for TRAJECTORY\n",
    "    Y_traj_pos_indices = []\n",
    "    Y_traj_dir_indices = []\n",
    "\n",
    "    # number of trajectory elements\n",
    "    w = 4\n",
    "    for i in range(0, 23, w): #TODO UPDATE THE RANGE\n",
    "        Y_traj_pos_indices = np.append(Y_traj_pos_indices, range(i,i+2)).astype(int)\n",
    "        Y_traj_dir_indices = np.append(Y_traj_dir_indices, range(i+2,i+4)).astype(int)\n",
    "\n",
    "    # lists to keep track of indices for JOINTS\n",
    "    Y_joint_pos_indices = []\n",
    "    Y_joint_vel_indices = []\n",
    "\n",
    "    # num of joint elements\n",
    "    w = 6\n",
    "    for i in range(24, 887, w): #TODO UPDATE THE RANGE\n",
    "        Y_joint_pos_indices = np.append(Y_joint_pos_indices, range(i,i+3)).astype(int)\n",
    "        Y_joint_vel_indices = np.append(Y_joint_vel_indices, range(i+3,i+6)).astype(int)\n",
    "\n",
    "    # OUTPUT Trajectory data\n",
    "    Ystd[Y_traj_pos_indices] = Ystd[Y_traj_pos_indices].mean()\n",
    "    Ystd[Y_traj_dir_indices] = Ystd[Y_traj_dir_indices].mean()\n",
    "\n",
    "    # OUTPUT Joint data \n",
    "    Ystd[Y_joint_pos_indices] = Ystd[Y_joint_pos_indices].mean()\n",
    "    Ystd[Y_joint_vel_indices] = Ystd[Y_joint_vel_indices].mean()\n",
    "\n",
    "    return Ymean, Ystd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape torch.Size([226, 961])\n",
      "Target shape torch.Size([226, 892])\n"
     ]
    }
   ],
   "source": [
    "# Preprocess Data\n",
    "Xmean, Xstd = preprocess_X_2Styles(X)\n",
    "Ymean, Ystd = preprocess_Y(Y)\n",
    "\n",
    "WEIGHTS_SAVE_PATH = 'C:/Users/Ana/Desktop/dev/pfnn-dev/unity-pfnn/Assets/Dev/Weights/test/'\n",
    "\n",
    "for i in range(Xstd.size):\n",
    "    if (Xstd[i]==0):\n",
    "        Xstd[i]=1\n",
    "for i in range(Ystd.size):\n",
    "    if (Ystd[i]==0):\n",
    "        Ystd[i]=1\n",
    "\n",
    "# save means and stds\n",
    "Xmean.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Xmean.bin')\n",
    "Ymean.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Ymean.bin')\n",
    "Xstd.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Xstd.bin')\n",
    "Ystd.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Ystd.bin')\n",
    "\n",
    "# normalize data \n",
    "X = (X - Xmean) / Xstd\n",
    "Y = (Y - Ymean) / Ystd\n",
    "\n",
    "# load data for PyTorch training\n",
    "# append phase as additional feature only for training NN\n",
    "input = torch.tensor(np.concatenate([X, P [..., np.newaxis]], axis=-1))\n",
    "target = torch.tensor(Y)\n",
    "\n",
    "print(f\"Input shape {input.shape}\")\n",
    "print(f\"Target shape {target.shape}\")\n",
    "\n",
    "dataset = TensorDataset(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00,  9.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 1.5815205124528744\n",
      "inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Loss: 1.276665727243227\n",
      "0.3048547852096475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30], Loss: 1.2490270298252457\n",
      "0.027638697417981195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30], Loss: 1.2102372136682398\n",
      "0.03878981615700594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30], Loss: 1.252356713921646\n",
      "0.04211950025340627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30], Loss: 1.1045167085188294\n",
      "0.10572050514941034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30], Loss: 0.8095944458529143\n",
      "0.29492226266591515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30], Loss: 0.7077431914787948\n",
      "0.10185125437411946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30], Loss: 0.6689796803625012\n",
      "0.038763511116293614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30], Loss: 0.6867987264480893\n",
      "0.01781904608558804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30], Loss: 0.5134231211746924\n",
      "0.15555655918780886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30], Loss: 0.5100221836833085\n",
      "0.0034009374913838153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30], Loss: 0.5020237558629661\n",
      "0.007998427820342435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30], Loss: 0.4609123616550879\n",
      "0.04111139420787818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30], Loss: 0.4911058677159789\n",
      "0.030193506060890996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30], Loss: 0.4555359954806881\n",
      "0.005376366174399794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30], Loss: 0.4717397240544796\n",
      "0.016203728573791487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30], Loss: 0.38835848270397044\n",
      "0.06717751277671768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Loss: 0.4023502539933126\n",
      "0.013991771289342148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30], Loss: 0.3393102162854954\n",
      "0.04904826641847504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30], Loss: 0.41721973715684063\n",
      "0.07790952087134523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30], Loss: 0.31603457450985556\n",
      "0.023275641775639844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30], Loss: 0.3512729998111566\n",
      "0.03523842530130106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30], Loss: 0.3068578761021674\n",
      "0.009176698407688144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30], Loss: 0.3242249697366199\n",
      "0.01736709363445249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30], Loss: 0.28481822670833334\n",
      "0.02203964939383407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30], Loss: 0.36019391652684524\n",
      "0.07537568981851189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30], Loss: 0.3205525940587578\n",
      "0.035734367350424456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30], Loss: 0.27335507928811736\n",
      "0.01146314742021598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30], Loss: 0.2846759015502073\n",
      "0.011320822262089913\n"
     ]
    }
   ],
   "source": [
    "# Define PFNN\n",
    "model = PhaseFunctionedNetwork(input_shape=input.shape[1], output_shape=target.shape[1], dropout=0.7)\n",
    "\n",
    "# Determine device for training \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Training variables\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "LR = 0.0001\n",
    "OPTIMIZER = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Train\n",
    "model, loss_history = train_pfnn_thresh(model, train_dataloader, optimizer=OPTIMIZER, num_epochs=EPOCHS, device=DEVICE, threshold=0.000001)\n",
    "\n",
    "# Save\n",
    "model.precompute_and_save_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
