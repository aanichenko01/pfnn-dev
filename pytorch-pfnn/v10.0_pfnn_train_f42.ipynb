{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from PhaseFunctionedNetwork import PhaseFunctionedNetwork\n",
    "from train_utils import train_pfnn\n",
    "\n",
    "# set seeds for reproduceability\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# DATA AUG\n",
    "# Style 1 is where the jump style was carefully labelled to blend between jump and idle\n",
    "# Style 2 is where jumps where just labelled as jumps and idle was labelled as idle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUND = 2\n",
    "\n",
    "def get_change_in_phase(phase_arr):\n",
    "    change_in_phase =  phase_arr[1:] - phase_arr[:-1]\n",
    "    change_in_phase[change_in_phase < 0] = (1.0 - phase_arr[:-1] + phase_arr[1:])[change_in_phase < 0]\n",
    "    change_in_phase = np.append(change_in_phase, change_in_phase[-1]) #TODO IF BREAKS append 2pi\n",
    "    return change_in_phase\n",
    "\n",
    "def load_data(action_name):\n",
    "    extension = \".txt\"\n",
    "    X_arr = np.float32(np.loadtxt(ROOT_PATH + INPUT_PATH + action_name + extension))\n",
    "    Y_arr = np.float32(np.loadtxt(ROOT_PATH + OUTPUT_PATH + action_name + extension))\n",
    "    \n",
    "    return X_arr, Y_arr\n",
    "\n",
    "def get_phase(X_arr):\n",
    "    P_arr = np.round(np.linspace(0, 0.99, num=X_arr.shape[0]), ROUND)\n",
    "    return P_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape: (1277, 960)\n",
      "Output data shape: (1277, 891)\n",
      "Phase data shape: (1277,)\n",
      "Delta phase shape: (1277,)\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = 'C:/Users/Ana/Desktop/dev/pfnn-dev/Export/aug_data/'\n",
    "INPUT_PATH = 'Input_'\n",
    "OUTPUT_PATH = 'Output_'\n",
    "\n",
    "file_count = sum(1 for filename in os.listdir(ROOT_PATH) if filename.endswith('.txt'))\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "P = np.empty(0)\n",
    "delta_phase = np.empty(0)\n",
    "\n",
    "for i in range(int(file_count/2)):\n",
    "    input_data, output_data = load_data(str(i))\n",
    "    phase_data = get_phase(input_data)\n",
    "    change_in_phase = get_change_in_phase(phase_data)\n",
    "\n",
    "    X.append(input_data)\n",
    "    Y.append(output_data)\n",
    "    P = np.append(P, phase_data)\n",
    "    delta_phase = np.append(delta_phase, change_in_phase)\n",
    "\n",
    "# stack all the arrays on top of each other\n",
    "X = np.vstack(X)\n",
    "Y = np.vstack(Y)\n",
    "delta_phase = delta_phase.flatten()\n",
    "P = P.flatten()\n",
    "\n",
    "# Y = np.concatenate([Y, delta_phase [..., np.newaxis]], axis=-1)\n",
    "# print stats \n",
    "print(f\"Input data shape: {X.shape}\")\n",
    "print(f\"Output data shape: {Y.shape}\")\n",
    "print(f\"Phase data shape: {P.shape}\")\n",
    "print(f\"Delta phase shape: {delta_phase.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape: (1349, 960)\n",
      "Output data shape: (1349, 892)\n",
      "Phase data shape: (1349,)\n",
      "Delta phase shape: (1349,)\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = 'C:/Users/Ana/Desktop/dev/pfnn-dev/Export/original/Stylev2/'\n",
    "INPUT_PATH = 'Input_'\n",
    "OUTPUT_PATH = 'Output_'\n",
    "\n",
    "# Load Data\n",
    "ROUND = 2\n",
    "\n",
    "X_idle = np.float32(np.loadtxt(ROOT_PATH + INPUT_PATH + 'Idle_Static.txt'))\n",
    "Y_idle = np.float32(np.loadtxt(ROOT_PATH + OUTPUT_PATH + 'Idle_Static.txt'))\n",
    "P_idle = np.round(np.append(np.linspace(0, 0.99, num=36), np.linspace(0, 0.99, num=36)), ROUND)\n",
    "delta_idle = get_change_in_phase(P_idle)\n",
    "\n",
    "X = np.concatenate((X, X_idle))\n",
    "Y = np.concatenate((Y, Y_idle))\n",
    "delta_phase = np.concatenate((delta_phase, delta_idle))\n",
    "P = np.concatenate((P, P_idle))\n",
    "\n",
    "Y = np.concatenate([Y, delta_phase [..., np.newaxis]], axis=-1)\n",
    "print(f\"Input data shape: {X.shape}\")\n",
    "print(f\"Output data shape: {Y.shape}\")\n",
    "print(f\"Phase data shape: {P.shape}\")\n",
    "print(f\"Delta phase shape: {delta_phase.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_X(X_arr):\n",
    "    Xmean, Xstd = X_arr.mean(axis=0), X_arr.std(axis=0)\n",
    "\n",
    "    # lists to keep track of indices for TRAJECTORY\n",
    "    X_traj_pos_indices = []\n",
    "    X_traj_dir_indices = []\n",
    "    X_traj_style_indices = []\n",
    "    X_traj_slope_indices = []\n",
    "\n",
    "    # number of eleements for each trajectory point\n",
    "    w = 8\n",
    "    for i in range(0, 95, w):\n",
    "        X_traj_pos_indices = np.append(X_traj_pos_indices, range(i,i+3)).astype(int)\n",
    "        X_traj_dir_indices = np.append(X_traj_dir_indices, range(i+3,i+5)).astype(int)\n",
    "        X_traj_slope_indices = np.append(X_traj_slope_indices, i+5).astype(int)\n",
    "        X_traj_style_indices = np.append(X_traj_style_indices, range(i+6,i+8)).astype(int)\n",
    "\n",
    "    # lists to keep track of indices for JOINTS\n",
    "    X_joint_pos_indices = []\n",
    "    X_joint_vel_indices = []\n",
    "\n",
    "    # num of elements for each joint\n",
    "    w = 6\n",
    "    for i in range(96, 959, w):\n",
    "        X_joint_pos_indices = np.append(X_joint_pos_indices, range(i,i+3)).astype(int)\n",
    "        X_joint_vel_indices = np.append(X_joint_vel_indices, range(i+3,i+6)).astype(int)\n",
    "\n",
    "    # INPUT Trajectory data\n",
    "    Xstd[X_traj_pos_indices] = Xstd[X_traj_pos_indices].mean()\n",
    "    Xstd[X_traj_dir_indices] = Xstd[X_traj_dir_indices].mean()\n",
    "    Xstd[X_traj_style_indices] = Xstd[X_traj_style_indices].mean()\n",
    "    Xstd[X_traj_slope_indices] = Xstd[X_traj_slope_indices].mean()\n",
    "\n",
    "    # INPUT Joint data --> This is where we weight the joints\n",
    "    # Xstd[X_joint_pos_indices] = Xstd[X_joint_pos_indices].mean() / (joint_weights * 0.1)\n",
    "    # Xstd[X_joint_vel_indices] = Xstd[X_joint_vel_indices].mean() / (joint_weights * 0.1)\n",
    "    Xstd[X_joint_pos_indices] = Xstd[X_joint_pos_indices].mean() \n",
    "    Xstd[X_joint_vel_indices] = Xstd[X_joint_vel_indices].mean()\n",
    "\n",
    "    return Xmean, Xstd\n",
    "\n",
    "def preprocess_Y(Y_arr):\n",
    "    Ymean, Ystd = Y_arr.mean(axis=0), Y_arr.std(axis=0)\n",
    "\n",
    "    # PREPROCESS OUTPUT Y\n",
    "    # lists to keep track of indices for TRAJECTORY\n",
    "    Y_traj_pos_indices = []\n",
    "    Y_traj_dir_indices = []\n",
    "\n",
    "    # number of trajectory elements\n",
    "    w = 4\n",
    "    for i in range(0, 23, w): #TODO UPDATE THE RANGE\n",
    "        Y_traj_pos_indices = np.append(Y_traj_pos_indices, range(i,i+2)).astype(int)\n",
    "        Y_traj_dir_indices = np.append(Y_traj_dir_indices, range(i+2,i+4)).astype(int)\n",
    "\n",
    "    # lists to keep track of indices for JOINTS\n",
    "    Y_joint_pos_indices = []\n",
    "    Y_joint_vel_indices = []\n",
    "\n",
    "    # num of joint elements\n",
    "    w = 6\n",
    "    for i in range(24, 887, w): #TODO UPDATE THE RANGE\n",
    "        Y_joint_pos_indices = np.append(Y_joint_pos_indices, range(i,i+3)).astype(int)\n",
    "        Y_joint_vel_indices = np.append(Y_joint_vel_indices, range(i+3,i+6)).astype(int)\n",
    "\n",
    "    # OUTPUT Trajectory data\n",
    "    Ystd[Y_traj_pos_indices] = Ystd[Y_traj_pos_indices].mean()\n",
    "    Ystd[Y_traj_dir_indices] = Ystd[Y_traj_dir_indices].mean()\n",
    "\n",
    "    # OUTPUT Joint data --> This is where we weight the joints\n",
    "    # Ystd[Y_joint_pos_indices] = Ystd[Y_joint_pos_indices].mean() / (joint_weights * 0.1)\n",
    "    # Ystd[Y_joint_vel_indices] = Ystd[Y_joint_vel_indices].mean() / (joint_weights * 0.1)\n",
    "    Ystd[Y_joint_pos_indices] = Ystd[Y_joint_pos_indices].mean()\n",
    "    Ystd[Y_joint_vel_indices] = Ystd[Y_joint_vel_indices].mean()\n",
    "    \n",
    "    # translational_vel_mean = (Ystd[-4] + Ystd[-2])/2\n",
    "    # Ystd[-4] = translational_vel_mean\n",
    "    # Ystd[-2] = translational_vel_mean\n",
    "\n",
    "    return Ymean, Ystd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape torch.Size([1349, 961])\n",
      "Target shape torch.Size([1349, 892])\n"
     ]
    }
   ],
   "source": [
    "# Preprocess Data\n",
    "Xmean, Xstd = preprocess_X(X)\n",
    "Ymean, Ystd = preprocess_Y(Y)\n",
    "\n",
    "WEIGHTS_SAVE_PATH = 'C:/Users/Ana/Desktop/dev/pfnn-dev/unity-pfnn/Assets/Dev/Weights/test/'\n",
    "\n",
    "for i in range(Xstd.size):\n",
    "    if (Xstd[i]==0):\n",
    "        Xstd[i]=1\n",
    "for i in range(Ystd.size):\n",
    "    if (Ystd[i]==0):\n",
    "        Ystd[i]=1\n",
    "\n",
    "# save means and stds\n",
    "Xmean.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Xmean.bin')\n",
    "Ymean.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Ymean.bin')\n",
    "Xstd.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Xstd.bin')\n",
    "Ystd.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Ystd.bin')\n",
    "\n",
    "# normalize data NOTE ORIGINAL DID THIS AFTER SAVING THE MEANS AND STD AS DONE HERE\n",
    "X = (X - Xmean) / Xstd\n",
    "Y = (Y - Ymean) / Ystd\n",
    "\n",
    "# load data for PyTorch training\n",
    "\n",
    "# append phase as additional feature only for training NN\n",
    "input = torch.tensor(np.concatenate([X, P [..., np.newaxis]], axis=-1))\n",
    "target = torch.tensor(Y)\n",
    "\n",
    "print(f\"Input shape {input.shape}\")\n",
    "print(f\"Target shape {target.shape}\")\n",
    "\n",
    "dataset = TensorDataset(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:04<00:00, 10.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.6122588814692934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.28526377274169634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.2648512172880565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.2696230750995994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.2443488565582706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.26239707544289137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.26653106378753016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.26925084193259774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.2585601337244871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.2811574903942121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.28948194489358664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.2701197358595824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.3188378182341738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.2970584310365018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.3014388689253245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.3192467851942515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.30893023656662577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.30014684823916526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.3126973090087078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:03<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.3054723904496885\n"
     ]
    }
   ],
   "source": [
    "# Define PFNN\n",
    "model = PhaseFunctionedNetwork(input_shape=input.shape[1], output_shape=target.shape[1], dropout=0.7)\n",
    "\n",
    "# Determine device for training \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Training variables\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LR = 0.001\n",
    "OPTIMIZER = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Train\n",
    "model = train_pfnn(model, train_dataloader, optimizer=OPTIMIZER, num_epochs=EPOCHS, device=DEVICE)\n",
    "\n",
    "# Save\n",
    "model.precompute_and_save_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
