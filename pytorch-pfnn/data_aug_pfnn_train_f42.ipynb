{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from PhaseFunctionedNetwork import PhaseFunctionedNetwork\n",
    "from train_utils import train_pfnn_thresh\n",
    "\n",
    "# set seeds for reproduceability\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# Style 1 - Idle\n",
    "# Style 2 - Walk\n",
    "# Style 3 - Jump \n",
    "\n",
    "# Expriments with all data varieties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUND = 2\n",
    "INPUT_PATH = 'Input_'\n",
    "OUTPUT_PATH = 'Output_'\n",
    "\n",
    "def get_change_in_phase(phase_arr):\n",
    "    change_in_phase =  phase_arr[1:] - phase_arr[:-1]\n",
    "    change_in_phase[change_in_phase < 0] = (1.0 - phase_arr[:-1] + phase_arr[1:])[change_in_phase < 0]\n",
    "    change_in_phase = np.append(change_in_phase, change_in_phase[-1]) #TODO IF BREAKS append 2pi\n",
    "    return change_in_phase\n",
    "\n",
    "def get_phase_acyclic(X_arr):\n",
    "    # P_arr = np.round(np.linspace(0, 0.99, num=X_arr.shape[0]), ROUND)\n",
    "    P_arr = np.linspace(0, 0.99, num=X_arr.shape[0])\n",
    "\n",
    "    return P_arr\n",
    "\n",
    "def get_phase_cyclic(X_arr, num_repetitions):\n",
    "    total_len = X_arr.shape[0]\n",
    "    \n",
    "    cycle_len = total_len // num_repetitions\n",
    "    cycle = np.linspace(0, 0.99, num=cycle_len, endpoint=False)\n",
    "    # Repeat\n",
    "    P_arr = np.tile(cycle, num_repetitions)\n",
    "\n",
    "    # If not long enough add from beggining of cycle\n",
    "    P_arr_len = len(P_arr)\n",
    "    if P_arr_len < total_len:\n",
    "        pad_to = total_len - P_arr_len\n",
    "        P_arr = np.concatenate([P_arr, cycle[:pad_to]])\n",
    "\n",
    "    # P_arr = np.round(P_arr, ROUND)\n",
    "    return P_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PREFIX = 'Input_'\n",
    "OUTPUT_PREFIX = 'Output_'\n",
    "\n",
    "EXTENSION = '.txt'\n",
    "\n",
    "def load_data(data_dir, action_num):\n",
    "    X_arr = np.float32(np.loadtxt(data_dir + INPUT_PREFIX + action_num + EXTENSION))\n",
    "    Y_arr = np.float32(np.loadtxt(data_dir + OUTPUT_PREFIX + action_num + EXTENSION))\n",
    "    \n",
    "    return X_arr, Y_arr\n",
    "\n",
    "def process_data(X_arr, Y_arr, P_arr, delta_phase_arr, num_files, data_dir, split_stats_arr, cyclic_action=True):\n",
    "    prev_data = sum(arr.shape[0] for arr in X_arr) + sum(arr.shape[0] for arr in Y_arr) \n",
    "    for i in range(int(num_files/2)):\n",
    "        input_data, output_data = load_data(data_dir, str(i))\n",
    "\n",
    "        if(cyclic_action):\n",
    "            phase_data = get_phase_cyclic(input_data, 3)\n",
    "        else:\n",
    "            phase_data = get_phase_acyclic(input_data)\n",
    "\n",
    "        change_in_phase = get_change_in_phase(phase_data)\n",
    "\n",
    "        X_arr.append(input_data)\n",
    "        Y_arr.append(output_data)\n",
    "        P_arr = np.append(P_arr, phase_data)\n",
    "        delta_phase_arr = np.append(delta_phase_arr, change_in_phase)\n",
    "\n",
    "    current_data = sum(arr.shape[0] for arr in X_arr) + sum(arr.shape[0] for arr in Y_arr)\n",
    "    split_stats_arr.append(current_data - prev_data)\n",
    "\n",
    "    return X_arr, Y_arr, P_arr, delta_phase_arr, split_stats_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEIGH THE JOINT (in particular all the hand and foot joints need to be weighted less)\n",
    "JOINT_NUM = 144\n",
    "\n",
    "joint_weights = np.array([\n",
    "    1,                                                  # HIPS\n",
    "    1, 1, 1,                                            # LEFT leg\n",
    "    1e-10, 1e-10, 1e-10, 1,                             # LEFT foot thumb\n",
    "    1,                                                  # LEFT foot toe base\n",
    "    1e-10, 1e-10, 1e-10, 1,                             # LEFT foot index\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # LEFT foot middle\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # LEFT foot ring\n",
    "    1, 1, 1,                                            # RIGHT leg\n",
    "    1e-10, 1e-10, 1e-10, 1,                             # RIGHT foot thumb\n",
    "    1,                                                  # RIGHT foot toe base\n",
    "    1e-10, 1e-10, 1e-10, 1,                             # RIGHT foot index\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # RIGHT foot middle\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # RIGHT foot ring\n",
    "    1, 1, 1, 1,                                         # SPINE\n",
    "    1, 1,                                               # LEFT shoulder\n",
    "    1, 1,                                               # LEFT arm\n",
    "    1,                                                  # LEFT hand\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # LEFT hand index\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # LEFT hand middle\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # LEFT hand ring\n",
    "    1, 1e-10, 1,                                        # LEFT wing feathers large\n",
    "    1, 1e-10, 1,                                        # LEFT wing feathers medium\n",
    "    1,                                                  # LEFT wing feathers small\n",
    "    1, 1, 1, 1, 1, 1, 1,                                # NECK\n",
    "    1,                                                  # HEAD\n",
    "    1e-10, 1e-10,                                       # JAW\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1e-10, 1e-10, 1e-10,    # TONUGE\n",
    "    1e-10, 1e-10, 1e-10,                                # LEFT eye\n",
    "    1e-10, 1e-10, 1e-10,                                # RIGHT eye\n",
    "    1, 1,                                               # RIGHT shoulder\n",
    "    1, 1,                                               # RIGHT arm\n",
    "    1,                                                  # RIGHT hand\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # RIGHT hand index\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # RIGHT hand middle\n",
    "    1e-10, 1e-10, 1e-10, 1e-10, 1,                      # RIGHT hand ring\n",
    "    1, 1e-10, 1,                                        # RIGHT wing feathers large\n",
    "    1, 1e-10, 1,                                        # RIGHT wing feathers medium\n",
    "    1,                                                  # RIGHT wing feathers small\n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1,                          # TAIL\n",
    "    1e-10, 1e-10, 1,                                    # LEFT tail feather\n",
    "    1e-10, 1e-10, 1,                                    # MIDDLE tail feather         \n",
    "    1e-10, 1e-10, 1                                     # RIGHT tail feather \n",
    "])\n",
    "\n",
    "# repeat weights for each joint to represent X, Y and Z\n",
    "joint_weights = joint_weights.repeat(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic processing of idle and jumps\n",
    "ROOT_DIR = 'C:/Users/Ana/Desktop/dev/pfnn-dev/Export/data_aug/v5.0/'\n",
    "IDLE_DATA_DIR = ROOT_DIR + 'idle/'\n",
    "JUMP_DATA_DIR = ROOT_DIR + 'jump/'\n",
    "\n",
    "split_stats = []\n",
    "X = []\n",
    "Y = []\n",
    "P = np.empty(0)\n",
    "delta_phase = np.empty(0)\n",
    "\n",
    "# Process idle data\n",
    "file_count = sum(1 for filename in os.listdir(IDLE_DATA_DIR) if filename.endswith('.txt'))\n",
    "X, Y, P, delta_phase, split_stats = process_data(X, Y, P, delta_phase, file_count, data_dir=IDLE_DATA_DIR, split_stats_arr=split_stats, cyclic_action=True)\n",
    "\n",
    "# Process jump data\n",
    "file_count = sum(1 for filename in os.listdir(JUMP_DATA_DIR) if filename.endswith('.txt'))\n",
    "X, Y, P, delta_phase, split_stats = process_data(X, Y, P, delta_phase, file_count, data_dir=JUMP_DATA_DIR, split_stats_arr=split_stats, cyclic_action=False)\n",
    "\n",
    "# COMMENT OUT TO PROCESS WALK DATA\n",
    "WALK_DATA_DIR = ROOT_DIR + 'walk/'\n",
    "input_data, output_data = load_data(WALK_DATA_DIR, \"0\")\n",
    "\n",
    "split_stats.append(input_data.shape[0] + output_data.shape[0])\n",
    "\n",
    "walk_cycle = np.concatenate((np.linspace(0, 0.5, num=17, endpoint=False), np.linspace(0.5, 0.99, num=21, endpoint=False)))\n",
    "phase_data = np.tile(walk_cycle, 10)[:377]\n",
    "change_in_phase = get_change_in_phase(phase_data)\n",
    "\n",
    "X.append(input_data)\n",
    "Y.append(output_data)\n",
    "P = np.append(P, phase_data)\n",
    "delta_phase = np.append(delta_phase, change_in_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape: (3085, 972)\n",
      "Output data shape: (3085, 892)\n",
      "Phase data shape: (3085,)\n",
      "Delta phase shape: (3085,)\n",
      "Action 0 = 2.33%\n",
      "Action 1 = 85.45%\n",
      "Action 2 = 12.22%\n"
     ]
    }
   ],
   "source": [
    "# stack all the arrays on top of each other\n",
    "X = np.vstack(X)\n",
    "Y = np.vstack(Y)\n",
    "delta_phase = delta_phase.flatten()\n",
    "P = P.flatten()\n",
    "Y = np.concatenate([Y, delta_phase [..., np.newaxis]], axis=-1)\n",
    "\n",
    "# print stats \n",
    "print(f\"Input data shape: {X.shape}\")\n",
    "print(f\"Output data shape: {Y.shape}\")\n",
    "print(f\"Phase data shape: {P.shape}\")\n",
    "print(f\"Delta phase shape: {delta_phase.shape}\")\n",
    "\n",
    "# Action 0 --> Idle\n",
    "# Action 1 --> Jump\n",
    "# Action 2 --> Walk\n",
    "# print data distribution stats (walk/idle) \n",
    "total_data = sum(data for data in split_stats)\n",
    "for i in range(len(split_stats)):\n",
    "    print(f\"Action {i} = {np.round(split_stats[i]/total_data * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_X_3Styles(X_arr):\n",
    "    Xmean, Xstd = X_arr.mean(axis=0), X_arr.std(axis=0)\n",
    "\n",
    "    # lists to keep track of indices for TRAJECTORY\n",
    "    X_traj_pos_indices = []\n",
    "    X_traj_dir_indices = []\n",
    "    X_traj_style_indices = []\n",
    "    X_traj_slope_indices = []\n",
    "\n",
    "    # number of eleements for each trajectory point\n",
    "    w = 9\n",
    "    for i in range(0, 107, w):\n",
    "        X_traj_pos_indices = np.append(X_traj_pos_indices, range(i,i+3)).astype(int)\n",
    "        X_traj_dir_indices = np.append(X_traj_dir_indices, range(i+3,i+5)).astype(int)\n",
    "        X_traj_slope_indices = np.append(X_traj_slope_indices, i+5).astype(int)\n",
    "        X_traj_style_indices = np.append(X_traj_style_indices, range(i+6,i+9)).astype(int)\n",
    "\n",
    "    # lists to keep track of indices for JOINTS\n",
    "    X_joint_pos_indices = []\n",
    "    X_joint_vel_indices = []\n",
    "\n",
    "    # num of elements for each joint\n",
    "    w = 6\n",
    "    for i in range(107, 971, w):\n",
    "        X_joint_pos_indices = np.append(X_joint_pos_indices, range(i,i+3)).astype(int)\n",
    "        X_joint_vel_indices = np.append(X_joint_vel_indices, range(i+3,i+6)).astype(int)\n",
    "\n",
    "    # INPUT Trajectory data\n",
    "    Xstd[X_traj_pos_indices] = Xstd[X_traj_pos_indices].mean()\n",
    "    Xstd[X_traj_dir_indices] = Xstd[X_traj_dir_indices].mean()\n",
    "    Xstd[X_traj_style_indices] = Xstd[X_traj_style_indices].mean()\n",
    "    Xstd[X_traj_slope_indices] = Xstd[X_traj_slope_indices].mean()\n",
    "\n",
    "    # INPUT Joint data --> This is where we weight the joints\n",
    "    Xstd[X_joint_pos_indices] = Xstd[X_joint_pos_indices].mean() / (joint_weights * 0.1)\n",
    "    Xstd[X_joint_vel_indices] = Xstd[X_joint_vel_indices].mean() / (joint_weights * 0.1)\n",
    "    # Xstd[X_joint_pos_indices] = Xstd[X_joint_pos_indices].mean() \n",
    "    # Xstd[X_joint_vel_indices] = Xstd[X_joint_vel_indices].mean()\n",
    "\n",
    "    return Xmean, Xstd\n",
    "\n",
    "def preprocess_X_2Styles(X_arr):\n",
    "    Xmean, Xstd = X_arr.mean(axis=0), X_arr.std(axis=0)\n",
    "\n",
    "    # lists to keep track of indices for TRAJECTORY\n",
    "    X_traj_pos_indices = []\n",
    "    X_traj_dir_indices = []\n",
    "    X_traj_style_indices = []\n",
    "    X_traj_slope_indices = []\n",
    "\n",
    "    # number of eleements for each trajectory point\n",
    "    w = 8\n",
    "    for i in range(0, 95, w):\n",
    "        X_traj_pos_indices = np.append(X_traj_pos_indices, range(i,i+3)).astype(int)\n",
    "        X_traj_dir_indices = np.append(X_traj_dir_indices, range(i+3,i+5)).astype(int)\n",
    "        X_traj_slope_indices = np.append(X_traj_slope_indices, i+5).astype(int)\n",
    "        X_traj_style_indices = np.append(X_traj_style_indices, range(i+6,i+8)).astype(int)\n",
    "\n",
    "    # lists to keep track of indices for JOINTS\n",
    "    X_joint_pos_indices = []\n",
    "    X_joint_vel_indices = []\n",
    "\n",
    "    # num of elements for each joint\n",
    "    w = 6\n",
    "    for i in range(96, 959, w):\n",
    "        X_joint_pos_indices = np.append(X_joint_pos_indices, range(i,i+3)).astype(int)\n",
    "        X_joint_vel_indices = np.append(X_joint_vel_indices, range(i+3,i+6)).astype(int)\n",
    "\n",
    "    # INPUT Trajectory data\n",
    "    Xstd[X_traj_pos_indices] = Xstd[X_traj_pos_indices].mean()\n",
    "    Xstd[X_traj_dir_indices] = Xstd[X_traj_dir_indices].mean()\n",
    "    Xstd[X_traj_style_indices] = Xstd[X_traj_style_indices].mean()\n",
    "    Xstd[X_traj_slope_indices] = Xstd[X_traj_slope_indices].mean()\n",
    "\n",
    "    # INPUT Joint data --> This is where we weight the joints\n",
    "    Xstd[X_joint_pos_indices] = Xstd[X_joint_pos_indices].mean() / (joint_weights * 0.1)\n",
    "    Xstd[X_joint_vel_indices] = Xstd[X_joint_vel_indices].mean() / (joint_weights * 0.1)\n",
    "    # Xstd[X_joint_pos_indices] = Xstd[X_joint_pos_indices].mean() \n",
    "    # Xstd[X_joint_vel_indices] = Xstd[X_joint_vel_indices].mean()\n",
    "\n",
    "    return Xmean, Xstd\n",
    "\n",
    "def preprocess_Y(Y_arr):\n",
    "    Ymean, Ystd = Y_arr.mean(axis=0), Y_arr.std(axis=0)\n",
    "\n",
    "    # PREPROCESS OUTPUT Y\n",
    "    # lists to keep track of indices for TRAJECTORY\n",
    "    Y_traj_pos_indices = []\n",
    "    Y_traj_dir_indices = []\n",
    "\n",
    "    # number of trajectory elements\n",
    "    w = 4\n",
    "    for i in range(0, 23, w): #TODO UPDATE THE RANGE\n",
    "        Y_traj_pos_indices = np.append(Y_traj_pos_indices, range(i,i+2)).astype(int)\n",
    "        Y_traj_dir_indices = np.append(Y_traj_dir_indices, range(i+2,i+4)).astype(int)\n",
    "\n",
    "    # lists to keep track of indices for JOINTS\n",
    "    Y_joint_pos_indices = []\n",
    "    Y_joint_vel_indices = []\n",
    "\n",
    "    # num of joint elements\n",
    "    w = 6\n",
    "    for i in range(24, 887, w): #TODO UPDATE THE RANGE\n",
    "        Y_joint_pos_indices = np.append(Y_joint_pos_indices, range(i,i+3)).astype(int)\n",
    "        Y_joint_vel_indices = np.append(Y_joint_vel_indices, range(i+3,i+6)).astype(int)\n",
    "\n",
    "    # OUTPUT Trajectory data\n",
    "    Ystd[Y_traj_pos_indices] = Ystd[Y_traj_pos_indices].mean()\n",
    "    Ystd[Y_traj_dir_indices] = Ystd[Y_traj_dir_indices].mean()\n",
    "\n",
    "    # OUTPUT Joint data --> This is where we weight the joints\n",
    "    Ystd[Y_joint_pos_indices] = Ystd[Y_joint_pos_indices].mean()\n",
    "    Ystd[Y_joint_vel_indices] = Ystd[Y_joint_vel_indices].mean()\n",
    "    \n",
    "    # translational_vel_mean = (Ystd[-4] + Ystd[-2])/2\n",
    "    # Ystd[-4] = translational_vel_mean\n",
    "    # Ystd[-2] = translational_vel_mean\n",
    "\n",
    "    return Ymean, Ystd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape torch.Size([3085, 973])\n",
      "Target shape torch.Size([3085, 892])\n"
     ]
    }
   ],
   "source": [
    "# Preprocess Data\n",
    "# Xmean, Xstd = preprocess_X_2Styles(X)\n",
    "Xmean, Xstd = preprocess_X_3Styles(X)\n",
    "Ymean, Ystd = preprocess_Y(Y)\n",
    "\n",
    "WEIGHTS_SAVE_PATH = 'C:/Users/Ana/Desktop/dev/pfnn-dev/unity-pfnn/Assets/Dev/Weights/test/'\n",
    "\n",
    "for i in range(Xstd.size):\n",
    "    if (Xstd[i]==0):\n",
    "        Xstd[i]=1\n",
    "for i in range(Ystd.size):\n",
    "    if (Ystd[i]==0):\n",
    "        Ystd[i]=1\n",
    "\n",
    "# save means and stds\n",
    "Xmean.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Xmean.bin')\n",
    "Ymean.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Ymean.bin')\n",
    "Xstd.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Xstd.bin')\n",
    "Ystd.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Ystd.bin')\n",
    "\n",
    "# normalize data NOTE ORIGINAL DID THIS AFTER SAVING THE MEANS AND STD AS DONE HERE\n",
    "X = (X - Xmean) / Xstd\n",
    "Y = (Y - Ymean) / Ystd\n",
    "\n",
    "# load data for PyTorch training\n",
    "\n",
    "# append phase as additional feature only for training NN\n",
    "input = torch.tensor(np.concatenate([X, P [..., np.newaxis]], axis=-1))\n",
    "target = torch.tensor(Y)\n",
    "\n",
    "print(f\"Input shape {input.shape}\")\n",
    "print(f\"Target shape {target.shape}\")\n",
    "\n",
    "dataset = TensorDataset(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:09<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.4672039961385224\n",
      "inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:09<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.9122365250898774\n",
      "0.554967471048645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:09<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.7875643914304491\n",
      "0.12467213365942831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.712250622869829\n",
      "0.07531376856062011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.6661827419714169\n",
      "0.04606788089841207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 11.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.6159950658827371\n",
      "0.0501876760886798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.5740583069823727\n",
      "0.04193675890036441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.5306351061279125\n",
      "0.043423200854460164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.49098910912751714\n",
      "0.039645997000395394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.46014516168007863\n",
      "0.030843947447438513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.4365646205770462\n",
      "0.023580541103032426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.4064953250718052\n",
      "0.03006929550524101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.39506213873504714\n",
      "0.01143318633675805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.36665169461254743\n",
      "0.028410444122499712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.3407317352617237\n",
      "0.02591995935082375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.3173156748114585\n",
      "0.023416060450265175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.3087259549010954\n",
      "0.008589719910363114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.28790615374315276\n",
      "0.02081980115794263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.2791522065519719\n",
      "0.008753947191180833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 11.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.26778504883918847\n",
      "0.01136715771278346\n"
     ]
    }
   ],
   "source": [
    "# Define PFNN\n",
    "model = PhaseFunctionedNetwork(input_shape=input.shape[1], output_shape=target.shape[1], dropout=0.7)\n",
    "\n",
    "# Determine device for training \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Training variables\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LR = 0.0001\n",
    "OPTIMIZER = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Train\n",
    "model, loss_history = train_pfnn_thresh(model, train_dataloader, optimizer=OPTIMIZER, num_epochs=EPOCHS, device=DEVICE, threshold=0.000001)\n",
    "\n",
    "# Save\n",
    "model.precompute_and_save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('v10.0_base_thresh_0.05', loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Ana/Desktop/dev/pfnn-dev/TrainingStats/v9.0_base_losshist.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# # Plot\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m v9_base \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Users/Ana/Desktop/dev/pfnn-dev/TrainingStats/v9.0_base_losshist.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m v10_base_patience \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/Ana/Desktop/dev/pfnn-dev/TrainingStats/v10.0_base_patience5_losshist.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m v10_base_thresh1\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/Ana/Desktop/dev/pfnn-dev/TrainingStats/v10.0_base_thresh0.01_losshist.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Ana\\anaconda3\\envs\\torch\\lib\\site-packages\\numpy\\lib\\npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Ana/Desktop/dev/pfnn-dev/TrainingStats/v9.0_base_losshist.npy'"
     ]
    }
   ],
   "source": [
    "# # Plot\n",
    "v9_base = np.load('C:/Users/Ana/Desktop/dev/pfnn-dev/TrainingStats/v9.0_base_losshist.npy')\n",
    "v10_base_patience = np.load('C:/Users/Ana/Desktop/dev/pfnn-dev/TrainingStats/v10.0_base_patience5_losshist.npy')\n",
    "v10_base_thresh1= np.load('C:/Users/Ana/Desktop/dev/pfnn-dev/TrainingStats/v10.0_base_thresh0.01_losshist.npy')\n",
    "v10_base_thresh5= np.load('C:/Users/Ana/Desktop/dev/pfnn-dev/TrainingStats/v10.0_base_thresh0.05_losshist.npy')\n",
    "\n",
    "# Create corresponding x values for each array\n",
    "# x1 = np.arange(len(v9_base))\n",
    "x2 = np.arange(len(v10_base_patience))\n",
    "x3 = np.arange(len(v10_base_thresh1))\n",
    "x4 = np.arange(len(v10_base_thresh5))\n",
    "\n",
    "# Plot both arrays on the same plot\n",
    "# plt.plot(x1, v9_base, label='Original')\n",
    "plt.plot(x2, v10_base_patience, label='patience=5')\n",
    "plt.plot(x3, v10_base_thresh1, label='threshold=0.01')\n",
    "plt.plot(x4, v10_base_thresh5, label='threshold=0.05')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
