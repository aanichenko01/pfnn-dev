{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PhaseFunctionedNetwork import PhaseFunctionedNetwork\n",
    "from train_utils import train_pfnn_patience\n",
    "from train_utils import train_pfnn_thresh\n",
    "\n",
    "\n",
    "# set seeds for reproduceability\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# Style 1 is where the jump style was carefully labelled to blend between jump and idle\n",
    "# Style 2 is where jumps where just labelled as jumps and idle was labelled as idle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Data \n",
    "ROOT_PATH = 'C:/Users/Ana/Desktop/dev/pfnn-dev/Export/v9.0_data/Stylev2/'\n",
    "INPUT_PATH = 'Input_'\n",
    "OUTPUT_PATH = 'Output_'\n",
    "\n",
    "def get_change_in_phase(phase_arr):\n",
    "    change_in_phase =  phase_arr[1:] - phase_arr[:-1]\n",
    "    change_in_phase[change_in_phase < 0] = (1.0 - phase_arr[:-1] + phase_arr[1:])[change_in_phase < 0]\n",
    "    change_in_phase = np.append(change_in_phase,  change_in_phase[-1]) #TODO IF BREAKS append 2pi\n",
    "    return change_in_phase\n",
    "\n",
    "def load_data(action_name):\n",
    "    X_arr = np.float32(np.loadtxt(ROOT_PATH + INPUT_PATH + action_name))\n",
    "    Y_arr = np.float32(np.loadtxt(ROOT_PATH + OUTPUT_PATH + action_name))\n",
    "    \n",
    "    return X_arr, Y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idle data shape: (72, 960), (72, 891), (72,), (72,)\n",
      "Horizflat data shape: (50, 960), (50, 891), (50,), (50,)\n",
      "Horizup data shape: (48, 960), (48, 891), (48,), (48,)\n",
      "Horizup data shape: (56, 960), (56, 891), (56,), (56,)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "ROUND = 2\n",
    "# Idle Data\n",
    "X_idle, Y_idle = load_data('Idle_Static.txt')\n",
    "P_idle = np.round(np.append(np.linspace(0, 0.99, num=36), np.linspace(0, 0.99, num=36)), ROUND)\n",
    "delta_idle = get_change_in_phase(P_idle)\n",
    "print(f\"Idle data shape: {X_idle.shape}, {Y_idle.shape}, {P_idle.shape}, {delta_idle.shape}\")\n",
    "\n",
    "# Jump HorizFlat\n",
    "X_jump_horizflat, Y_jump_horizflat = load_data('Jump_HorizFlat.txt')\n",
    "P_jump_horizflat = np.round(np.linspace(0, 0.99, num=50), ROUND)\n",
    "delta_jump_horizflat = get_change_in_phase(P_jump_horizflat)\n",
    "print(f\"Horizflat data shape: {X_jump_horizflat.shape}, {Y_jump_horizflat.shape}, {P_jump_horizflat.shape}, {delta_jump_horizflat.shape}\")\n",
    "\n",
    "# Jump HorizUp\n",
    "X_jump_horizup, Y_jump_horizup = load_data('Jump_HorizUp.txt')\n",
    "P_jump_horizup = np.round(np.linspace(0, 0.99, num=48), ROUND)\n",
    "delta_jump_horizup = get_change_in_phase(P_jump_horizup)\n",
    "print(f\"Horizup data shape: {X_jump_horizup.shape}, {Y_jump_horizup.shape}, {P_jump_horizup.shape}, {delta_jump_horizup.shape}\")\n",
    "\n",
    "# Jump HorizDown\n",
    "X_jump_horizdown, Y_jump_horizdown = load_data('Jump_HorizDown.txt')\n",
    "P_jump_horizdown = np.round(np.linspace(0, 0.99, num=56), ROUND)\n",
    "delta_jump_horizdown = get_change_in_phase(P_jump_horizdown)\n",
    "print(f\"Horizup data shape: {X_jump_horizdown.shape}, {Y_jump_horizdown.shape}, {P_jump_horizdown.shape}, {delta_jump_horizdown.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_X(X_arr):\n",
    "    Xmean, Xstd = X_arr.mean(axis=0), X_arr.std(axis=0)\n",
    "\n",
    "    # lists to keep track of indices for TRAJECTORY\n",
    "    X_traj_pos_indices = []\n",
    "    X_traj_dir_indices = []\n",
    "    X_traj_style_indices = []\n",
    "    X_traj_slope_indices = []\n",
    "\n",
    "    # number of eleements for each trajectory point\n",
    "    w = 8\n",
    "    for i in range(0, 95, w):\n",
    "        X_traj_pos_indices = np.append(X_traj_pos_indices, range(i,i+3)).astype(int)\n",
    "        X_traj_dir_indices = np.append(X_traj_dir_indices, range(i+3,i+5)).astype(int)\n",
    "        X_traj_slope_indices = np.append(X_traj_slope_indices, i+5).astype(int)\n",
    "        X_traj_style_indices = np.append(X_traj_style_indices, range(i+6,i+8)).astype(int)\n",
    "\n",
    "    # lists to keep track of indices for JOINTS\n",
    "    X_joint_pos_indices = []\n",
    "    X_joint_vel_indices = []\n",
    "\n",
    "    # num of elements for each joint\n",
    "    w = 6\n",
    "    for i in range(96, 959, w):\n",
    "        X_joint_pos_indices = np.append(X_joint_pos_indices, range(i,i+3)).astype(int)\n",
    "        X_joint_vel_indices = np.append(X_joint_vel_indices, range(i+3,i+6)).astype(int)\n",
    "\n",
    "    # INPUT Trajectory data\n",
    "    Xstd[X_traj_pos_indices] = Xstd[X_traj_pos_indices].mean()\n",
    "    Xstd[X_traj_dir_indices] = Xstd[X_traj_dir_indices].mean()\n",
    "    Xstd[X_traj_style_indices] = Xstd[X_traj_style_indices].mean()\n",
    "    Xstd[X_traj_slope_indices] = Xstd[X_traj_slope_indices].mean()\n",
    "\n",
    "    # INPUT Joint data --> This is where we weight the joints\n",
    "    # Xstd[X_joint_pos_indices] = Xstd[X_joint_pos_indices].mean() / (joint_weights * 0.1)\n",
    "    # Xstd[X_joint_vel_indices] = Xstd[X_joint_vel_indices].mean() / (joint_weights * 0.1)\n",
    "    Xstd[X_joint_pos_indices] = Xstd[X_joint_pos_indices].mean() \n",
    "    Xstd[X_joint_vel_indices] = Xstd[X_joint_vel_indices].mean()\n",
    "\n",
    "    return Xmean, Xstd\n",
    "\n",
    "def preprocess_Y(Y_arr):\n",
    "    Ymean, Ystd = Y_arr.mean(axis=0), Y_arr.std(axis=0)\n",
    "\n",
    "    # PREPROCESS OUTPUT Y\n",
    "    # lists to keep track of indices for TRAJECTORY\n",
    "    Y_traj_pos_indices = []\n",
    "    Y_traj_dir_indices = []\n",
    "\n",
    "    # number of trajectory elements\n",
    "    w = 4\n",
    "    for i in range(0, 23, w): #TODO UPDATE THE RANGE\n",
    "        Y_traj_pos_indices = np.append(Y_traj_pos_indices, range(i,i+2)).astype(int)\n",
    "        Y_traj_dir_indices = np.append(Y_traj_dir_indices, range(i+2,i+4)).astype(int)\n",
    "\n",
    "    # lists to keep track of indices for JOINTS\n",
    "    Y_joint_pos_indices = []\n",
    "    Y_joint_vel_indices = []\n",
    "\n",
    "    # num of joint elements\n",
    "    w = 6\n",
    "    for i in range(24, 887, w): #TODO UPDATE THE RANGE\n",
    "        Y_joint_pos_indices = np.append(Y_joint_pos_indices, range(i,i+3)).astype(int)\n",
    "        Y_joint_vel_indices = np.append(Y_joint_vel_indices, range(i+3,i+6)).astype(int)\n",
    "\n",
    "    # OUTPUT Trajectory data\n",
    "    Ystd[Y_traj_pos_indices] = Ystd[Y_traj_pos_indices].mean()\n",
    "    Ystd[Y_traj_dir_indices] = Ystd[Y_traj_dir_indices].mean()\n",
    "\n",
    "    # OUTPUT Joint data --> This is where we weight the joints\n",
    "    # Ystd[Y_joint_pos_indices] = Ystd[Y_joint_pos_indices].mean() / (joint_weights * 0.1)\n",
    "    # Ystd[Y_joint_vel_indices] = Ystd[Y_joint_vel_indices].mean() / (joint_weights * 0.1)\n",
    "    Ystd[Y_joint_pos_indices] = Ystd[Y_joint_pos_indices].mean()\n",
    "    Ystd[Y_joint_vel_indices] = Ystd[Y_joint_vel_indices].mean()\n",
    "    \n",
    "    # translational_vel_mean = (Ystd[-4] + Ystd[-2])/2\n",
    "    # Ystd[-4] = translational_vel_mean\n",
    "    # Ystd[-2] = translational_vel_mean\n",
    "\n",
    "    return Ymean, Ystd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape torch.Size([170, 961])\n",
      "Target shape torch.Size([170, 892])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate Data into indivudal X, Y, P Arrays\n",
    "# X = np.concatenate((X_idle, X_jump_horizflat, X_jump_horizup, X_jump_horizdown))\n",
    "# Y = np.concatenate((Y_idle, Y_jump_horizflat, Y_jump_horizup, Y_jump_horizdown))\n",
    "# P = np.concatenate((P_idle, P_jump_horizflat, P_jump_horizup, P_jump_horizdown))\n",
    "# delta_phase = np.concatenate((delta_idle, delta_jump_horizflat, delta_jump_horizup, delta_jump_horizdown))\n",
    "# Y = np.concatenate([Y, delta_phase [..., np.newaxis]], axis=-1)\n",
    "\n",
    "X = np.concatenate((X_idle, X_jump_horizflat, X_jump_horizup))\n",
    "Y = np.concatenate((Y_idle, Y_jump_horizflat, Y_jump_horizup))\n",
    "P = np.concatenate((P_idle, P_jump_horizflat, P_jump_horizup))\n",
    "delta_phase = np.concatenate((delta_idle, delta_jump_horizflat, delta_jump_horizup))\n",
    "Y = np.concatenate([Y, delta_phase [..., np.newaxis]], axis=-1)\n",
    "\n",
    "# Preprocess Data\n",
    "Xmean, Xstd = preprocess_X(X)\n",
    "Ymean, Ystd = preprocess_Y(Y)\n",
    "\n",
    "WEIGHTS_SAVE_PATH = 'C:/Users/Ana/Desktop/dev/pfnn-dev/unity-pfnn/Assets/Dev/Weights/test/'\n",
    "\n",
    "for i in range(Xstd.size):\n",
    "    if (Xstd[i]==0):\n",
    "        Xstd[i]=1\n",
    "for i in range(Ystd.size):\n",
    "    if (Ystd[i]==0):\n",
    "        Ystd[i]=1\n",
    "\n",
    "# save means and stds\n",
    "Xmean.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Xmean.bin')\n",
    "Ymean.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Ymean.bin')\n",
    "Xstd.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Xstd.bin')\n",
    "Ystd.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Ystd.bin')\n",
    "\n",
    "# normalize data NOTE ORIGINAL DID THIS AFTER SAVING THE MEANS AND STD AS DONE HERE\n",
    "X = (X - Xmean) / Xstd\n",
    "Y = (Y - Ymean) / Ystd\n",
    "\n",
    "# load data for PyTorch training\n",
    "\n",
    "# append phase as additional feature only for training NN\n",
    "input = torch.tensor(np.concatenate([X, P [..., np.newaxis]], axis=-1))\n",
    "target = torch.tensor(Y)\n",
    "\n",
    "print(f\"Input shape {input.shape}\")\n",
    "print(f\"Target shape {target.shape}\")\n",
    "\n",
    "dataset = TensorDataset(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 1.4193697484066365\n",
      "inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 12.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/500], Loss: 1.5907108209048986\n",
      "0.17134107249826203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 12.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/500], Loss: 1.4003146380540477\n",
      "0.01905511035258889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 12.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/500], Loss: 1.4204265376711829\n",
      "0.02011189961713522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/500], Loss: 1.4668431399144166\n",
      "0.06652850186036896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 12.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/500], Loss: 1.1939653100260816\n",
      "0.20634932802796602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 12.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/500], Loss: 0.9738957174620624\n",
      "0.22006959256401926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 12.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/500], Loss: 0.8578258626429118\n",
      "0.11606985481915055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 12.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/500], Loss: 0.8019320310079655\n",
      "0.05589383163494632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 12.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/500], Loss: 0.6679014073460783\n",
      "0.13403062366188723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 12.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/500], Loss: 0.6289911279456523\n",
      "0.03891027940042602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 12.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/500], Loss: 0.5897108794251839\n",
      "0.03928024852046841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 12.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/500], Loss: 0.5566770745803251\n",
      "0.03303380484485874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/500], Loss: 0.5706215639050748\n",
      "0.013944489324749676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/500], Loss: 0.5567887188549828\n",
      "0.00011164427465770732\n",
      "Training stopped as loss did not improve by set threshold of 0.01.\n"
     ]
    }
   ],
   "source": [
    "# Define PFNN\n",
    "model = PhaseFunctionedNetwork(input_shape=input.shape[1], output_shape=target.shape[1], dropout=0.7)\n",
    "\n",
    "# Determine device for training \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Training variables\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500\n",
    "LR = 0.0001\n",
    "OPTIMIZER = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Train\n",
    "# model, loss_hist = train_pfnn_patience(model, train_dataloader, optimizer=OPTIMIZER, num_epochs=EPOCHS, device=DEVICE, patience=5)\n",
    "model, loss_hist = train_pfnn_thresh(model, train_dataloader, optimizer=OPTIMIZER, num_epochs=EPOCHS, device=DEVICE, threshold=0.01)\n",
    "\n",
    "# Save\n",
    "model.precompute_and_save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save loss for later plotting\n",
    "np.save('v9.0_base_thresh0.01_losshist.npy', loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot\n",
    "# v9_base = np.load('C:/Users/Ana/Desktop/dev/pfnn-dev/TrainingStats/v9.0_base_losshist.npy')\n",
    "# v9_withHorizDown = np.load('C:/Users/Ana/Desktop/dev/pfnn-dev/TrainingStats/v9.0_withHorizDown_losshist.npy')\n",
    "\n",
    "# # Create corresponding x values for each array\n",
    "# x1 = np.arange(len(v9_base))\n",
    "# x2 = np.arange(len(v9_withHorizDown))\n",
    "\n",
    "# # Plot both arrays on the same plot\n",
    "# plt.plot(x1, v9_base, label='Array 1')\n",
    "# plt.plot(x2, v9_withHorizDown, label='Array 2')\n",
    "\n",
    "# # Add title and labels\n",
    "# plt.title('Training Loss')\n",
    "# plt.xlabel('Index')\n",
    "# plt.ylabel('Value')\n",
    "\n",
    "# # Add a legend\n",
    "# plt.legend()\n",
    "\n",
    "# # Display the plot\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
