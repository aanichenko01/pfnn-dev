{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from PhaseFunctionedNetwork import PhaseFunctionedNetwork\n",
    "from train_utils import train_pfnn\n",
    "\n",
    "# set seeds for reproduceability\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# 2 styles (jump and idle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Data \n",
    "ROOT_PATH = 'C:/Users/Ana/Desktop/dev/pfnn-dev/Export/'\n",
    "INPUT_PATH = 'Input_'\n",
    "OUTPUT_PATH = 'Output_'\n",
    "\n",
    "def get_change_in_phase(phase_arr):\n",
    "    change_in_phase =  phase_arr[1:] - phase_arr[:-1]\n",
    "    change_in_phase[change_in_phase < 0] = (1.0 - phase_arr[:-1] + phase_arr[1:])[change_in_phase < 0]\n",
    "    change_in_phase = np.append(change_in_phase,  change_in_phase[-1]) #TODO IF BREAKS append 2pi\n",
    "    return change_in_phase\n",
    "\n",
    "def load_data(action_name):\n",
    "    X_arr = np.float32(np.loadtxt(ROOT_PATH + INPUT_PATH + action_name))\n",
    "    Y_arr = np.float32(np.loadtxt(ROOT_PATH + OUTPUT_PATH + action_name))\n",
    "    \n",
    "    return X_arr, Y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idle data shape: (72, 960), (72, 891), (72,), (72,)\n",
      "Horizup data shape: (48, 960), (48, 891), (48,), (48,)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "ROUND = 2\n",
    "# Idle Data\n",
    "X_idle, Y_idle = load_data('Idle_Static.txt')\n",
    "P_idle = np.round(np.append(np.linspace(0, 0.99, num=36), np.linspace(0, 0.99, num=36)), ROUND)\n",
    "delta_idle = get_change_in_phase(P_idle)\n",
    "print(f\"Idle data shape: {X_idle.shape}, {Y_idle.shape}, {P_idle.shape}, {delta_idle.shape}\")\n",
    "\n",
    "# Jump HorizFlat\n",
    "# X_jump_horizflat, Y_jump_horizflat = load_data('Jump_HorizFlat.txt')\n",
    "# P_jump_horizflat = np.round(np.linspace(0, 0.99, num=50), ROUND)\n",
    "# delta_jump_horizflat = get_change_in_phase(P_jump_horizflat)\n",
    "# print(f\"Horizflat data shape: {X_jump_horizflat.shape}, {Y_jump_horizflat.shape}, {P_jump_horizflat.shape}, {delta_jump_horizflat.shape}\")\n",
    "\n",
    "# Jump HorizUp\n",
    "X_jump_horizup, Y_jump_horizup = load_data('Jump_HorizUp.txt')\n",
    "P_jump_horizup = np.round(np.linspace(0, 0.99, num=48), ROUND)\n",
    "delta_jump_horizup = get_change_in_phase(P_jump_horizup)\n",
    "print(f\"Horizup data shape: {X_jump_horizup.shape}, {Y_jump_horizup.shape}, {P_jump_horizup.shape}, {delta_jump_horizup.shape}\")\n",
    "\n",
    "# # Jump HorizDown\n",
    "# X_jump_horizdown, Y_jump_horizdown = load_data('Jump_HorizDown.txt')\n",
    "# P_jump_horizdown = np.round(np.linspace(0, 0.99, num=56), ROUND)\n",
    "# delta_jump_horizdown = get_change_in_phase(P_jump_horizdown)\n",
    "# print(f\"Horizup data shape: {X_jump_horizdown.shape}, {Y_jump_horizdown.shape}, {P_jump_horizdown.shape}, {delta_jump_horizdown.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.0, 0.5, 17).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.     , 0.03125, 0.0625 , 0.09375, 0.125  , 0.15625, 0.1875 ,\n",
       "       0.21875, 0.25   , 0.28125, 0.3125 , 0.34375, 0.375  , 0.40625,\n",
       "       0.4375 , 0.46875, 0.5    ])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.0, 0.5, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = np.concatenate((np.linspace(0.0, 0.5, num=16, endpoint=False), np.linspace(0.5, 0.99, num=25), np.linspace(0, 0.99, num=7)))\n",
    "# test = np.concatenate((np.linspace(0, 0.99, num=8), np.linspace(0, 0.5, num=8, endpoint=False), np.linspace(0.5, 0.99, num=12, endpoint=False), np.linspace(0.0, 0.99, num=20)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizup data shape: (48, 960), (48, 891), (48,), (48,)\n"
     ]
    }
   ],
   "source": [
    "# Jump HorizUp (better phase labelling)\n",
    "X_jump_horizup, Y_jump_horizup = load_data('Jump_HorizUp.txt')\n",
    "P_jump_horizup = np.round(np.linspace(0, 0.99, num=48), ROUND)\n",
    "delta_jump_horizup = get_change_in_phase(P_jump_horizup)\n",
    "print(f\"Horizup data shape: {X_jump_horizup.shape}, {Y_jump_horizup.shape}, {P_jump_horizup.shape}, {delta_jump_horizup.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_X(X_arr):\n",
    "    Xmean, Xstd = X_arr.mean(axis=0), X_arr.std(axis=0)\n",
    "\n",
    "    # lists to keep track of indices for TRAJECTORY\n",
    "    X_traj_pos_indices = []\n",
    "    X_traj_dir_indices = []\n",
    "    X_traj_style_indices = []\n",
    "    X_traj_slope_indices = []\n",
    "\n",
    "    # number of eleements for each trajectory point\n",
    "    w = 8\n",
    "    for i in range(0, 95, w):\n",
    "        X_traj_pos_indices = np.append(X_traj_pos_indices, range(i,i+3)).astype(int)\n",
    "        X_traj_dir_indices = np.append(X_traj_dir_indices, range(i+3,i+5)).astype(int)\n",
    "        X_traj_slope_indices = np.append(X_traj_slope_indices, i+5).astype(int)\n",
    "        X_traj_style_indices = np.append(X_traj_style_indices, range(i+6,i+8)).astype(int)\n",
    "\n",
    "    # lists to keep track of indices for JOINTS\n",
    "    X_joint_pos_indices = []\n",
    "    X_joint_vel_indices = []\n",
    "\n",
    "    # num of elements for each joint\n",
    "    w = 6\n",
    "    for i in range(96, 959, w):\n",
    "        X_joint_pos_indices = np.append(X_joint_pos_indices, range(i,i+3)).astype(int)\n",
    "        X_joint_vel_indices = np.append(X_joint_vel_indices, range(i+3,i+6)).astype(int)\n",
    "\n",
    "    # INPUT Trajectory data\n",
    "    Xstd[X_traj_pos_indices] = Xstd[X_traj_pos_indices].mean()\n",
    "    Xstd[X_traj_dir_indices] = Xstd[X_traj_dir_indices].mean()\n",
    "    Xstd[X_traj_style_indices] = Xstd[X_traj_style_indices].mean()\n",
    "    Xstd[X_traj_slope_indices] = Xstd[X_traj_slope_indices].mean()\n",
    "\n",
    "    # INPUT Joint data --> This is where we weight the joints\n",
    "    # Xstd[X_joint_pos_indices] = Xstd[X_joint_pos_indices].mean() / (joint_weights * 0.1)\n",
    "    # Xstd[X_joint_vel_indices] = Xstd[X_joint_vel_indices].mean() / (joint_weights * 0.1)\n",
    "    Xstd[X_joint_pos_indices] = Xstd[X_joint_pos_indices].mean() \n",
    "    Xstd[X_joint_vel_indices] = Xstd[X_joint_vel_indices].mean()\n",
    "\n",
    "    return Xmean, Xstd\n",
    "\n",
    "def preprocess_Y(Y_arr):\n",
    "    Ymean, Ystd = Y_arr.mean(axis=0), Y_arr.std(axis=0)\n",
    "\n",
    "    # PREPROCESS OUTPUT Y\n",
    "    # lists to keep track of indices for TRAJECTORY\n",
    "    Y_traj_pos_indices = []\n",
    "    Y_traj_dir_indices = []\n",
    "\n",
    "    # number of trajectory elements\n",
    "    w = 4\n",
    "    for i in range(0, 23, w): #TODO UPDATE THE RANGE\n",
    "        Y_traj_pos_indices = np.append(Y_traj_pos_indices, range(i,i+2)).astype(int)\n",
    "        Y_traj_dir_indices = np.append(Y_traj_dir_indices, range(i+2,i+4)).astype(int)\n",
    "\n",
    "    # lists to keep track of indices for JOINTS\n",
    "    Y_joint_pos_indices = []\n",
    "    Y_joint_vel_indices = []\n",
    "\n",
    "    # num of joint elements\n",
    "    w = 6\n",
    "    for i in range(24, 887, w): #TODO UPDATE THE RANGE\n",
    "        Y_joint_pos_indices = np.append(Y_joint_pos_indices, range(i,i+3)).astype(int)\n",
    "        Y_joint_vel_indices = np.append(Y_joint_vel_indices, range(i+3,i+6)).astype(int)\n",
    "\n",
    "    # OUTPUT Trajectory data\n",
    "    Ystd[Y_traj_pos_indices] = Ystd[Y_traj_pos_indices].mean()\n",
    "    Ystd[Y_traj_dir_indices] = Ystd[Y_traj_dir_indices].mean()\n",
    "\n",
    "    # OUTPUT Joint data --> This is where we weight the joints\n",
    "    # Ystd[Y_joint_pos_indices] = Ystd[Y_joint_pos_indices].mean() / (joint_weights * 0.1)\n",
    "    # Ystd[Y_joint_vel_indices] = Ystd[Y_joint_vel_indices].mean() / (joint_weights * 0.1)\n",
    "    Ystd[Y_joint_pos_indices] = Ystd[Y_joint_pos_indices].mean()\n",
    "    Ystd[Y_joint_vel_indices] = Ystd[Y_joint_vel_indices].mean()\n",
    "    \n",
    "    # translational_vel_mean = (Ystd[-4] + Ystd[-2])/2\n",
    "    # Ystd[-4] = translational_vel_mean\n",
    "    # Ystd[-2] = translational_vel_mean\n",
    "\n",
    "    return Ymean, Ystd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape torch.Size([120, 961])\n",
      "Target shape torch.Size([120, 892])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate Data into indivudal X, Y, P Arrays\n",
    "# X = np.concatenate((X_idle, X_jump_horizflat, X_jump_horizup, X_jump_horizdown))\n",
    "# Y = np.concatenate((Y_idle, Y_jump_horizflat, Y_jump_horizup, Y_jump_horizdown))\n",
    "# P = np.concatenate((P_idle, P_jump_horizflat, P_jump_horizup, P_jump_horizdown))\n",
    "# delta_phase = np.concatenate((delta_idle, delta_jump_horizflat, delta_jump_horizup, delta_jump_horizdown))\n",
    "# Y = np.concatenate([Y, delta_phase [..., np.newaxis]], axis=-1)\n",
    "\n",
    "X = np.concatenate((X_idle, X_jump_horizup))\n",
    "Y = np.concatenate((Y_idle, Y_jump_horizup))\n",
    "P = np.concatenate((P_idle, P_jump_horizup))\n",
    "delta_phase = np.concatenate((delta_idle, delta_jump_horizup))\n",
    "Y = np.concatenate([Y, delta_phase [..., np.newaxis]], axis=-1)\n",
    "\n",
    "# Preprocess Data\n",
    "Xmean, Xstd = preprocess_X(X)\n",
    "Ymean, Ystd = preprocess_Y(Y)\n",
    "\n",
    "WEIGHTS_SAVE_PATH = 'C:/Users/Ana/Desktop/dev/pfnn-dev/unity-pfnn/Assets/Dev/Weights/test/'\n",
    "\n",
    "for i in range(Xstd.size):\n",
    "    if (Xstd[i]==0):\n",
    "        Xstd[i]=1\n",
    "for i in range(Ystd.size):\n",
    "    if (Ystd[i]==0):\n",
    "        Ystd[i]=1\n",
    "\n",
    "# save means and stds\n",
    "Xmean.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Xmean.bin')\n",
    "Ymean.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Ymean.bin')\n",
    "Xstd.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Xstd.bin')\n",
    "Ystd.astype(np.float32).tofile(WEIGHTS_SAVE_PATH + 'Ystd.bin')\n",
    "\n",
    "# normalize data NOTE ORIGINAL DID THIS AFTER SAVING THE MEANS AND STD AS DONE HERE\n",
    "X = (X - Xmean) / Xstd\n",
    "Y = (Y - Ymean) / Ystd\n",
    "\n",
    "# load data for PyTorch training\n",
    "\n",
    "# append phase as additional feature only for training NN\n",
    "input = torch.tensor(np.concatenate([X, P [..., np.newaxis]], axis=-1))\n",
    "target = torch.tensor(Y)\n",
    "\n",
    "print(f\"Input shape {input.shape}\")\n",
    "print(f\"Target shape {target.shape}\")\n",
    "\n",
    "dataset = TensorDataset(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 1.7088094412689308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Loss: 1.1278064379262607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 11.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Loss: 0.6933887352176122\n"
     ]
    }
   ],
   "source": [
    "# Define PFNN\n",
    "model = PhaseFunctionedNetwork(input_shape=input.shape[1], output_shape=target.shape[1], dropout=0.7)\n",
    "\n",
    "# Determine device for training \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Training variables\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "LR = 0.001\n",
    "OPTIMIZER = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Train\n",
    "model = train_pfnn(model, train_dataloader, optimizer=OPTIMIZER, num_epochs=EPOCHS, device=DEVICE)\n",
    "\n",
    "# Save\n",
    "model.precompute_and_save_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
